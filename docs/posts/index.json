[{"content":"アウトプット強化月間2本目は、MongoDBのちょっとした操作に関する備忘録です。業務ではDocumentDBを使っているのですが、基本的にMongoDBと扱いは同じなのでMongoDBで説明していきます（個人で使うには無料枠があるという理由もあり）。\nやりたいこと 以下のようなコレクションがあったとします。なお簡略化のために _id は省いています。\n1 2 3 4 5 6 7 8 9 10 [ { \u0026#34;name\u0026#34;:\u0026#34;ヴィッセル神戸\u0026#34;, \u0026#34;players\u0026#34;:{\u0026#34;1\u0026#34;:\u0026#34;前川\u0026#34;,\u0026#34;2\u0026#34;:\u0026#34;飯野\u0026#34;,\u0026#34;3\u0026#34;:\u0026#34;トゥーレル\u0026#34;} } { \u0026#34;name\u0026#34;:\u0026#34;ガンバ大阪\u0026#34;, \u0026#34;players\u0026#34;:{\u0026#34;1\u0026#34;:\u0026#34;東口\u0026#34;,\u0026#34;2\u0026#34;:\u0026#34;福岡\u0026#34;,\u0026#34;3\u0026#34;:\u0026#34;半田\u0026#34;} } ] J1リーグのチームごとにドキュメントが存在し、チーム情報が保存されているイメージです。この時、背番号がkeyで選手名がvalueとなっている辞書型データがあり、 playersというフィールドがこのデータを保持しています。\nまさにネストしている状態ですが、このデータの中から特定の選手のデータを消したり、追加することは当然考えられます（選手の移籍ですね）。今回はこのデータ処理方法についてPyMongoでどのように操作するかまとめます。\nMongoDBではupdate系のメソッドにおいて $unset、 $set という演算子が存在しており、これらを実現することができます。\n$unset で一部を削除更新する 具体例として、ヴィッセル神戸の背番号3トゥーレル選手が脱退してしまったとしましょう（起きてほしくないですが）。この場合のプログラムの一例は以下となります。\n1 2 3 4 5 6 7 8 9 10 11 12 from pymongo.mongo_client import MongoClient from pymongo.server_api import ServerApi mongo_uri = \u0026#34;接続先情報\u0026#34; # コレクションへのアクセス client = MongoClient(mongo_uri, server_api=ServerApi(\u0026#34;1\u0026#34;)) db = client.j1 collection = db.teams collection.update_one(filter={\u0026#34;name\u0026#34;: \u0026#34;ヴィッセル神戸\u0026#34;}, update={\u0026#34;$unset\u0026#34;: {\u0026#34;players.3\u0026#34;: \u0026#34;\u0026#34;}}) ポイントはネストしている分のフィールド名を players.3のように.でつないでいることです。valueとして空文字を指定していますが、$unset演算子においてはここに何を入れても問題ありません。\nなお、指定したフィールド名が存在しない場合は何も起きません。この辺りは公式ドキュメントを参考にするとよいと思います。\n$set で一部を追加更新する トゥーレルが脱退してしまった状態は悲しいので、元に戻したいと思います。やり方は先ほどの $unset を $set に変えるだけです。\n1 2 3 4 5 6 7 8 9 10 11 12 from pymongo.mongo_client import MongoClient from pymongo.server_api import ServerApi mongo_uri = \u0026#34;接続先情報\u0026#34; # コレクションへのアクセス client = MongoClient(mongo_uri, server_api=ServerApi(\u0026#34;1\u0026#34;)) db = client.j1 collection = db.teams collection.update_one(filter={\u0026#34;name\u0026#34;: \u0026#34;ヴィッセル神戸\u0026#34;}, update={\u0026#34;$set\u0026#34;: {\u0026#34;players.3\u0026#34;: \u0026#34;トゥーレル\u0026#34;}}) なお、$set と $unset は同時に使うことができます。例えばですが「トゥーレル選手が移籍し、代わりに背番号64のマタ選手が入ってきた」みたいな状況を考えると、以下のようになります。\n1 2 3 4 collection.update_one( filter={\u0026#34;name\u0026#34;: \u0026#34;ヴィッセル神戸\u0026#34;}, update={\u0026#34;$set\u0026#34;:{\u0026#34;players.64\u0026#34;: \u0026#34;マタ\u0026#34;},\u0026#34;$unset\u0026#34;: {\u0026#34;players.3\u0026#34;: \u0026#34;\u0026#34;}} ) まとめ MongoDBのネストされたデータの操作について紹介いたしました。MongoDB（DocumentDB）に関しては今後触る機会が増えそうな気がするので、継続してキャッチアップや検証を進めていきたいと思っています。\n","description":"MongoDBをPyMongoで触っているときにドキュメントのバリューが辞書型（ネストしている）データの中から、特定の要素を削除（$unset）することがあったのでやり方のメモ","id":0,"section":"posts","tags":["Python","PyMongo","MongoDB"],"title":"MongoDBのネストされたデータの一部を $unset を利用して削除する","uri":"https://rakuichi4817.github.io/posts/pymongo-unset/"},{"content":"11月からアウトプット強化月間として継続的にブログ投稿していこうと思います。目標は週に2、3本で、基本的には技術系にしたいと思っています。途中で息切れした場合は関係ないネタも投稿するかもです。\n強化月間1本目はFastAPI関連のネタです。以前投稿した「 FastAPI×MKDocs（×GitHub Pages）でドキュメント生成」で、FastAPIで生成したSwaggerドキュメントをMKDocs側に反映し、GitHubPagesで展開するという内容を紹介しました。\n今回はAPIサーバを起動したときにAPIと同じポートにドキュメントページを展開するというものになります。ついでにDockerのマルチステージを使って、ソースのビルドも自動で行っています（この辺りについて詳細は触れません）。\n正直GitHub Pagesで展開すればよいのですが、仕事の中でいろいろ事情があって今回の内容を試した経験があり、メモがてらに残していきます。\n実際に作成されたページ例（同じlocalhost:8000に展開）↓\nドキュメントページ\nFastAPIによるSwagger\n基本構成 ファイル構成 紹介するコードは以下リポジトリで見ることができます。\nファイル構成は次の通りです。本記事で取り上げる内容にはコメントをつけています。\n1 2 3 4 5 6 7 8 9 10 11 12 13 rakuapi/ ├── .devcontainer/ ├── .vscode/ ├── app/ │ └── main.py # FastAPIのコード ├── docs/ │ └── index.md ├── .gitignore ├── Dockerfile # ドキュメントページをビルドする ├── Pipfile ├── Pipfile.lock ├── README.md └── mkdocs.yml # mkdocsの設定ファイル Dockerマルチステージの役割について マルチステージビルドを利用して、極力本番環境に無駄なものを入れないようにしています。本番環境ビルダーや開発用については詳しく触れません。\nmkdocs-builderステージでは、後述するmkdocsのページビルド作業を自動で行い、ビルドされた静的ファイルを本番環境ステージにコピーしています。\nこのようにすることで、\n開発者自身がソースをビルド ビルド後のコードを管理 といった作業が必要がなくなります。\nflowchart TB\rbase[\"ベースイメージ\n（python:3.11-slim）\"]\rdevcontainer[\"開発用\n（devcontainer用）\"]\rbuilder[\"本番環境ビルダー\n（Pythonライブラリのインストール）\"]\rmkdocs-builder[\"ドキュメントビルダー\n（MKDocsによるページビルド）\"]\rapp[\"本番環境\"]\rbase----\u003e devcontainer\rbase---\u003e builder\rbase----\u003e mkdocs-builder\rbase----\u003e app\rbuilder-.Pythonライブラリソースのみコピー.-\u003e app\rmkdocs-builder-.ビルドしたドキュメントソースのコピー.-\u003e app\rDockerfileの内容をそのまま貼っておきます。もっとこうしたほうが良いよ！等のアドバイスや指摘はチャットからお願いします。\nなお、Pythonのライブラリ管理にはPipenvを使っていますが、PipenvとDockerを組み合わせる際の話は過去記事の「Pipenv、Docker（マルチステージビルド）、devcontainerで開発環境と本番環境を分ける」を参照ください。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # ----------ベースイメージの指定---------- FROM python:3.11-slim AS base ARG workdir=\u0026#34;/rakuapi\u0026#34; WORKDIR $workdir RUN apt-get update \u0026amp;\u0026amp; pip install --upgrade pip # ----------開発用(.devcontainerが接続する用---------- FROM base AS devcontainer # devcontainer上では仮想環境を作って開発する RUN apt-get install -y git \\ \u0026amp;\u0026amp; pip install pipenv # ----------本番環境用ビルダー---------- FROM base as builder RUN pip install pipenv # ライブラリをシステムへ直接書き込む COPY Pipfile Pipfile.lock $workdir/ RUN pipenv sync --system # ----------ドキュメントビルダー---------- FROM base as mkdocs-builder # mkdocs用ライブラリを入れる RUN pip install mkdocs mkdocs-material mkdocs-render-swagger-plugin mkdocs-awesome-pages-plugin WORKDIR /build COPY ./docs /build/docs COPY mkdocs.yml /build/ RUN mkdocs build # ----------本番APP用---------- FROM base AS app # ビルダーで展開したライブラリをアプリ用コンテナにコピー COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages/ COPY --from=builder /usr/local/bin/uvicorn /usr/local/bin/uvicorn COPY --from=mkdocs-builder ./build/site /rakuapi/site COPY ./app $workdir/app EXPOSE 8000 HEALTHCHECK CMD curl --fail \u0026lt;http://localhost:8000/_stcore/health\u0026gt; ENTRYPOINT [\u0026#34;uvicorn\u0026#34;, \u0026#34;app.main:app\u0026#34;, \u0026#34;--host\u0026#34;, \u0026#34;0.0.0.0\u0026#34;, \u0026#34;--port\u0026#34;, \u0026#34;8000\u0026#34;] 各ファイル詳細 簡単に各ファイルの内容を紹介しておきます。\nmkdocs.yml：MKDocs まずMKDocsの設定ファイルであるmkdocs.ymlの説明をします。といっても、今回の内容を満たすことだけを考えるとあまり設定する必要はありません。GitHubのほうを見てもらうといろいろ書いていますが、本記事において必要な部分のみを抜粋します。\n1 2 3 4 5 site_name: rakuapi site_description: FastAPI×MKDocsのサンプル site_author: Rakuichi docs_dir: docs ドキュメントページのもとになるソースファイルを配置するディレクトリを docs_dir で指定します。今回の場合「docs」になるため上記の設定となります。mkdocsでビルドした静的ファイルはデフォルトで「site」に保存されるため、明示的な指定はしていません（もちろん明示的に指定することもできます）。\n私が用意したDockerfileでは、この「site」ディレクトリのみを「mkdocs-builder」ステージから「app」ステージへコピーしていることがわかると思います。 app/main.py：FastAPI 続いてFastAPI側のコードを紹介します。FastAPIで静的ファイルを展開する方法は公式ドキュメントに載っています。\n公式ドキュメント：https://fastapi.tiangolo.com/ja/tutorial/static-files/\n私のコードでは以下のように「site」ディレクトリが存在しているかどうかで、静的ファイルをマウントするかどうかを分けています。理由は開発環境で「site」ディレクトリが存在しないため、分岐がない場合エラーとなってしまうのを防ぐためです。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import os from fastapi import FastAPI from fastapi.staticfiles import StaticFiles site_dir = \u0026#34;site\u0026#34; app = FastAPI() @app.get(\u0026#34;/\u0026#34;) async def root(): return {\u0026#34;message\u0026#34;: \u0026#34;Hello World\u0026#34;} if os.path.exists(site_dir): # サイトページが存在していたらマウントする app.mount(\u0026#34;/devdocs\u0026#34;, StaticFiles(directory=site_dir, html=True), name=\u0026#34;site\u0026#34;) これだけ用意すれば、あとは最初に用意したDockerコンテナを立ち上げると、ページ上部に乗せた画像のようにAPIと同じlocalhost:8000上でビルドしたページを確認することができます。\nまとめ 今回は、FastAPIの機能を使ってMKDocsでビルドしたページを展開する方法について紹介しました。なんだか書いてる割合の多くがDocker部分になった気がしますが\u0026hellip;。ビルドを自動化する所はGitHub Actionsを使ってしまえばいいので、GitHub Pagesに展開する場合に応用することもできると思います。\nFastAPIを使って静的ファイルを表示する方法自体はいろいろなものに応用できるので、NextJS等でビルドした後のソースとかに置き換えることも可能です。フロントエンドの勉強もしていきたい\u0026hellip;。\n","description":"MKDocsでビルドした静的ファイルを、FastAPI の StaticFiles を使ってサーバ起動時に同時に展開する方法についてメモ書き。（Dockerのマルチステージを使ってmkdocsの自動ビルドも）","id":1,"section":"posts","tags":["Python","Pipenv","FastAPI","Docker","MKDocs"],"title":"FastAPI × MKDocs （ × Docker ）でAPIサーバとドキュメントページを同時に展開する","uri":"https://rakuichi4817.github.io/posts/fastapi-mkdocs/"},{"content":"Windows上でPipenvを使用し、Pythonバージョンを指定して仮想環境を作成しようとしたとき、Python Launcher管理下にある指定Pythonバージョンを見つけられず、エラー「Warning: Python ○○ was not found on your system\u0026hellip;」が出る問題の対策を紹介します。\n状況と原因 問題が起きる環境は以下の通りです。\nWindows11 Python公式のインストーラを使用、環境変数にパスは通さずPythonランチャー経由で実行管理（以下バージョンのインストール） Python3.11 Python3.10 この状況でPipenvを使って仮想環境を作成していきます。Python3.11側にPipenvを入れている状態で、Python3.10の仮想環境を作ります。通常のPipenvと同じようにコマンドを実行するとエラーになります。\n1 2 3 4 5 6 $ py -m pipenv --python 3.10 Warning: Python 3.10 was not found on your system... Neither \u0026#39;pyenv\u0026#39; nor \u0026#39;asdf\u0026#39; could be found to install Python. You can specify specific versions of Python with: $ pipenv --python path\\to\\python Python3.10を入れているのにPipenvが見つけられていません。原因は、「Pythonランチャー経由でPythonを実行しており、各バージョンのPython自体（Python.exe）の環境変数を通していない」 からとなります。\nPythonインストーラーでインストールするときに環境変数に通してしまえば解決はするのですが、Windows上では複数バージョンの管理が怪しくなるのでしたくありません。\n解決法 解決方法は仮想環境を作成する際に直接Pythonの実行ファイルのパスを通してあげると通ります。もしかしたらほかにも方法があるかもしれませんので、解決策の1つだと思ってもらえれば。\nまずはPythonランチャーが管理しているPythonリストを表示します。\n1 2 3 $ py --list-paths -V:3.11 * C:\\Users\\rakuichi\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -V:3.10 C:\\Users\\rakuichi\\AppData\\Local\\Programs\\Python\\Python310\\python.exe 今回は3.10を使って仮想環境を作るので以下のようなコマンドになります。\n1 py -m pipenv --python=C:\\Users\\rakuichi\\AppData\\Local\\Programs\\Python\\Python310\\python.exe これで無事仮想環境を作成することができます。既存のPipfileより環境を再現したい場合は、上記コマンドに install または syncをつけましょう。\n課題 連携されたPipfileから環境を再現する際、普通であればいちいちPythonのパスを指定しなくても良いです。しかし、今回のような環境では以下のような手順になってしまいます。\n連携されたPipfileを確認しPythonバージョンを確認 バージョンのパスを確認 パスを指定しながら環境再現コマンドを実行 少し手間だと感じます。\n結論 やっぱりDockerを使いましょう。\n","description":"Windows上でPipenvを使用し、Pythonバージョンを指定して仮想環境を作成しようとしたとき、Python Launcher管理下にある指定Pythonバージョンを見つけられず、エラー「Warning: Python ○○ was not found on your system...」が出る問題の解決法をメモしておきます。","id":2,"section":"posts","tags":["Python","Pipenv","環境構築"],"title":"Windows（Python Launcher）のPipenvでバージョンを指定して仮想環境を作ると失敗する問題の解決法","uri":"https://rakuichi4817.github.io/posts/pipenv-pylauncher/"},{"content":"今回は商品紹介になります。過去に「WEXLEY SHELDRAKE BACKPACK 紹介」という記事でバックパックを紹介したのですが、新しいバックパックを購入したので、そちらのレビューをしていきます。この記事に関することで質問したいことや気になる点があれば、右下のチャットよりご連絡ください！\n今回購入したのは 「Able Carry」 というブランドの 「Max Backpack」 になります。\n公式サイト→ https://ablecarry.jp/\nMax Backpack: 巾着付き Able Carryについて Able Carryはクラウドファンディングで資金調達した香港発のブランドのようです。以下紹介記事の引用です。\nAble Carryは香港の小さなチームから生まれたブランドで、2018年にKickstarter（クラウドファンディング・プラットフォーム）で資金を調達しプロジェクトをスタートさせました。\n都市に溶け込みながら快適性を追求し、バックパックの底部までストラップが伸びた独自のAフレーム構造にすることで、これまでと全く異なる背負い心地を実現しているのが特徴です。\n引用記事\nhttps://www.oshmans.co.jp/buyers_select/article/488\n私はたまたまInstagramで見つけましたが、まだまだ日本では有名でないブランドではないでしょうか？しかし、海外のバックパックレビューサイトでは高い評価を受けており、非常に使用感やデザインの良いバックパックを提供しています。\n※海外のバックパック情報をまとめているサイト→ PACK HACKER（Max Backpackのレビューページ） かなり気に入っているので、今回購入した「Max Backpack」以外の商品も買い替えタイミングで検討していきたいと考えています。\n購入背景 1~3泊程度の旅行を1つのバックパックで済ませたかった マンティス26の新バージョンに不満がある ガジェットが多いのでうまく収納できる物が良い 以前紹介した WEXLEY「SHELDRAKE BACKPACK」を現在も日常使いしているのですが、こちらは容量が17Ｌでコンパクトなサイズ感となっております。（このあたりは以前書いた記事を読んでいただければと思います。）\nまた、Arc’teryx「マンティス 26 バックパック」の新しいバージョン（過去の記事では旧バージョン）も所有していますが、容量は26Lです。しかし、新しいバージョンでは個人的に改悪されたと感じ、あまり満足していませんでした。特に、肩ひもが細く薄くなったため、重い荷物を入れると肩に負荷がかかる点が気になっています。\n基本的には出社時やちょっとしたお出かけの際にはSHELDRAKE BACKPACKを使用し、荷物が多くなった場合にはマンティス26を使い分けていました。しかし、荷物が多い私の場合、1泊以上するとマンティス26の容量が微妙に足りなくなってきました。また、上記の改悪を感じていたため、新しい大き目のリュックを購入することにしました。\n商品仕様 以下、公式サイトの引用です。\n¥46,200 税込\n大き目サイズで仕事やお出かけ、旅行までもカバーしてくれる究極のバックパック 。重い荷物を入れても快適に持ち運べるトラベル機能が満載のアイテムです。使う人の可能性をMAXに引き出します。\n対応ノートPCサイズ:17インチのデバイスが入ります(41 x 28 x 4 cm)\n素材: X-Pac + コーデュラ1000Dナイロン\n容量: 30L\n重量: 1800g\n寸法: 高さ52 x 幅32 x 奥行き20 cm\n良かった点・ウーンな点のまとめ 先にポイントをまとめておきます。\n良かった点 圧倒的容量なのにデザインがシュッとしている 収納場所の分割が適度 メイン収納にカラビナをつけられる場所がたくさんある 1日背負っていても疲れにくい 質感が良い ウーンな点 気軽に買える金額ではない 少し重い 良かった点 容量、見た目、背負い心地 まずは、当然ですが、めちゃくちゃ荷物が入ります。その上、見た目がキレイにまとまっています。下の写真では、左から「Max backpack」、「マンティス26」、「SHELDRAKE BACKPACK」となっています。高さは最も高くなっていますが、厚みがマンティスとほぼ同じのため、荷物をたくさん入れても膨らむような印象はありません。マンティスは良くも悪くもすごく膨らみますからね。\n質感もしっかりしていますし、シンプルながら地味でもなく個人的にはばっちりのデザインです。\nバックパック比較1\nマンティスより厚みはほぼ同じ\n実際に1泊の出張で、PCやその他のガジェット、衣類や化粧品などを入れて利用しましたが、かなり余裕がありました。また、結構な時間バッグを背負って過ごしましたが、肩ひもがしっかりしていて厚みもあるので、重さの割に負担が軽減されました。Able Carryのバックパックは、軽量であることが強みの1つで、背負い心地も良いです。新バージョンのマンティス26と比較しても、十分に優れていると思います。\n収納スペースについて バックパックによっては、収納量が多くても意外と使いにくかったりすることもありますが、こちらはかなり使いやすかったです。\nメイン収納 まず、メインの収納スペースです。下の画像の通り、一般的なファイルを収納してもこの高さの余裕があります。奥行きは若干わかりにくいですが、13〜18cm程度と思っていただければよいと思います（底の方が狭い）。外側の開閉部分にも2か所、ちょっとした収納スペースがあります。\nファイルを入れて\nカラビナをつける部分\n内側にボトル入れ\nまた、カラビナをつける部分がたくさん用意されており、写真ではわかりやすいように白いフックもつけています。高い位置に小物入れをひっかければより便利な使い方ができそうです。さらに、ボトルを入れられるところもあります。MaxBackpackは基本的にボトル入れが内側にある設計になっているので見た目がすっきりします。\nPCなどを入れるサブ収納 Max Backpackのグッドポイントの1つとして、PCなどを入れる収納がメイン収納とは別になっている点があります。出張などでPCなどを持ち運ぶとき、頻繁に出し入れするPCやiPadなどと出し入れする機会の少ない荷物が一緒に入っていると不便です。\n自分はここにPCやタブレット、書籍などを入れて持ち運んでいます。また、ファスナー付きの小物入れには目薬や画面拭きを入れています。\nファスナー付き小物入れ\nPC用のクッション付き収納\n浅めの収納\nその他サブ収納 上記の2つの大きな収納以外に、細かい収納が4つあります。サイドにはボトルや折り畳み傘などを入れることができる細長い収納が2つあります。一番外側には財布などを入れることができる収納が1つあります。背中側の頂点には、iPhoneなどがすっぽり入る薄い収納があります。\nやはり、ボトルや折り畳み傘を隠しながら収納できるのが良いですね。注意点としては、サイドの収納に物を入れるとメイン収納が多少圧迫される点です。\nボトルや折り畳み傘を収納可\n財布等を収納可\nボトル等収納可\n小物入れ\nウーンな点 値段は間違いなくウーンな点になるでしょう。数年前は3万円弱で買えたそうですが、円安のせいなのかブランド力が上がったせいなのか、現在は46,200円というなかなかの強気設定です。自分はバックパックが好きなので購入しましたが、人におススメしにくい価格だと思います。ただ、MaxBackpackより小さいサイズの商品は2万円台だったので、ちょっと良いバックパックが欲しい方にはお勧めできると思います。\n重さに関しては単体で1.8kgあるのでお世辞にも軽いとは言えません。背負ってしまえばそこまで気にならないですが、マンティス26が1kgを切っていることを考えると、ここはマイナスポイントでしょう。大きさを考えても女性にはあまりお勧めできない印象です。\n実際に背負っている写真などは公式のinstagramが参考になるかと思います↓\nこの投稿をInstagramで見る Able Carry(@ablecarry)がシェアした投稿\n総合評価 ウーンな点も書きましたが、（値段以外は！）大満足です！ 数日の旅行であればこちらのバックパックだけで問題なさそうですし、中にポーチなどを入れてしまえば観光の時は楽になりますしね。\n冒頭にも書きましたが、こちらの商品の情報はおそらくまだまだ少ないとおもいますので、気になることは気軽に質問してもらえたらと思います！右下のチャットボタンよりご連絡いただければ、返信可能なタイミングで対応させていただきます！（一度ブラウザを閉じてしまうと消える可能性があります。）\nその他参考になる動画 ","description":"大きくて背負いやすいバックパックを求めて、Able CarryのMax Backpackを購入したので感想でもまとめてみます。","id":3,"section":"posts","tags":["日用品","ガジェット"],"title":"Able CarryのMax Backpackを買ってみた","uri":"https://rakuichi4817.github.io/posts/max-backpack/"},{"content":"久しぶりの投稿です（n回目）。\n最近、Pythonで環境を作るときにDockerで環境を作るようにしており、そこで利用している設定についてメモ代わりに書いておこうと思います。今まではPipenvの仮想環境だけで対応していたのですが、ホストマシンの影響を受けることが少なくなく、Dockerを使うようにしています。\n実現したかった全体像 実装の参考にしたページは、本ページ下部の参考にまとめています。\n本ページで紹介する構成で、自分が達成したかった内容は以下項目です。\nPythonアプリ（サンプルはStreamlitで作る）の開発環境を作る PythonライブラリはPipenvで管理する Dockerのマルチステージビルドを利用して開発環境と本番環境を分ける 極力イメージサイズを小さくしたい 本番環境ではPipenvの仮想環境を作らない 開発環境ではPipenvの仮想環境を作って開発する 開発環境にはVSCodeのDevContainerで接続する 接続したコンテナ上でGitHubにsshアクセスしたい Pythonのライブラリ管理にPoetryも検討しているのですが、まだ移行できずにいるのでPipenvを使っています。Pipenvは仮想環境を構築する際に仮想環境用のファイルを用意するので、既存環境とすみわけができて便利なのですが、本番環境では必要ありません。\nPipenvでは--systemオプションをつけることで、システム側に直接書き込むことができるので、こちらをうまく活用して本番環境には最低限の要素のみ導入するようにします。\nGitに関しても開発環境のみ導入すれば問題ないので、Dockerのマルチステージビルド（Multi-stage builds）を利用して実現していきます。\n実際のコード 一通り見たい方は以下のGitHubから確認していただければと思います。\nDockerfile マルチステージビルドを使い、極力キャッシュを利用できるような構成にしたつもりですが、まだまだ無駄もあるかと思います。改善点があれば右下のチャットからぜひ教えていただければと思います。\n構成の参考には参考に乗せている資料にとてもお世話になりました。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # -----ベースイメージの指定----- FROM python:3.10-slim AS base ARG workdir=\u0026#34;/workspace\u0026#34; WORKDIR $workdir RUN apt-get update \u0026amp;\u0026amp; pip install --upgrade pip[label](https://speakerdeck.com/revcomm_inc/pythonnitotutenoyoriyoidockerfilewokao-eru) # -----本番環境用ビルダー----- FROM base as builder RUN pip install pipenv # ライブラリをシステムへ直接書き込む COPY Pipfile Pipfile.lock $workdir/ RUN pipenv sync --system EXPOSE 8501 # -----本番APP用------ FROM base AS app HEALTHCHECK CMD curl --fail \u0026lt;http://localhost:8501/_stcore/health\u0026gt; # ビルダーで展開したライブラリをアプリ用コンテナにコピー COPY --from=builder /usr/local/lib/python3.10/site-packages /usr/local/lib/python3.10/site-packages/ COPY --from=builder /usr/local/bin/streamlit /usr/local/bin/streamlit COPY . $workdir ENTRYPOINT streamlit run app/main.py --server.port=8501 --server.address=0.0.0.0 # -----開発用(.devcontainerが接続する用)----- FROM base AS development # devcontainer上では仮想環境を作って開発する RUN apt-get install -y git \\ \u0026amp;\u0026amp; pip install pipenv devcontainer.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 { \u0026#34;name\u0026#34;: \u0026#34;python-app\u0026#34;, \u0026#34;build\u0026#34;: { \u0026#34;context\u0026#34;: \u0026#34;..\u0026#34;, \u0026#34;dockerfile\u0026#34;: \u0026#34;../Dockerfile\u0026#34;, \u0026#34;target\u0026#34;: \u0026#34;development\u0026#34; }, \u0026#34;workspaceFolder\u0026#34;: \u0026#34;/workspace\u0026#34;, \u0026#34;workspaceMount\u0026#34;: \u0026#34;source=${localWorkspaceFolder},target=/workspace,type=bind\u0026#34;, \u0026#34;customizations\u0026#34;: { \u0026#34;vscode\u0026#34;: { \u0026#34;extensions\u0026#34;: [ \u0026#34;njpwerner.autodocstring\u0026#34;, \u0026#34;mhutchie.git-graph\u0026#34;, \u0026#34;MS-CEINTL.vscode-language-pack-ja\u0026#34;, \u0026#34;ms-python.python\u0026#34;, \u0026#34;ms-python.vscode-pylance\u0026#34;, \u0026#34;ionutvmi.path-autocomplete\u0026#34;, \u0026#34;DavidAnson.vscode-markdownlint\u0026#34;, \u0026#34;ms-toolsai.jupyter\u0026#34;, \u0026#34;redhat.vscode-yaml\u0026#34;, \u0026#34;bierner.markdown-preview-github-styles\u0026#34;, \u0026#34;yzhang.markdown-all-in-one\u0026#34; ] } }, \u0026#34;postCreateCommand\u0026#34;: \u0026#34;pipenv install --dev\u0026#34; } targetを指定することで、どのステージに対してアクセスするか指定できます。extensionsで指定している拡張機能は個人的によく使うものを入れているだけなので、必要がなければ抜いてください。\npostCreateCommandを用いて、VSCodeから開発環境へアクセスしたとき（最初にコンテナを作成した時）にPipenvの仮想環境を作成しています。開発段階では利用するライブラリを変えることもあるかと思うので、仮想環境を作成する形を残しています。\n各環境へのアクセスの仕方 本番環境のビルドと実行は以下コマンドになります。--targetオプションを利用することで、マルチステージビルドのどのステージをビルドするか指定できます。\n1 2 3 4 # ビルド $ docker build . --target app -t python-sample-app # アプリの起動 $ docker run -p 8501:8501 python-sample-app 開発環境へアクセスする際は、VSCodeのDevConteiner拡張で「Reopen In Container」を選択すればオッケーです。\n参考 Docker構成の参考（とても勉強になりました） Streamlit×Dockerの参考 Pipenv×Dockerの参考 DevContainer上からSSHでGitHubにアクセスする ","description":"PipenvでPythonのライブラリを管理しつつ、Dockerでマルチステージビルドを採用し、VSCodeのdevcontainerを利用して開発環境と本番環境を分ける方法についてメモ代わりにまとめます。サンプルアプリとしてStreamlitを採用しています","id":4,"section":"posts","tags":["Python","Pipenv","Streamlit","Docker","環境構築"],"title":"Pipenv、Docker（マルチステージビルド）、devcontainerで開発環境と本番環境を分ける","uri":"https://rakuichi4817.github.io/posts/pipenv-docker/"},{"content":"以前投稿した記事「FastAPI×Streamlitでアプリ開発（Getリクエスト）」で、FastAPIとStreamlitを利用し、Pythonのみでバックエンドとフロントエンドを分離したアプリを作成しました。\nどうせ練習するなら、合わせてドキュメントも作ってしまおうと思い、PythonでMarkdownを静的サイトへ変換できる静的サイトジェネレータ MKDocs を利用してみることにしました。\nリポジトリは以下になります。\nなお、本記事の方法を使って実際に作成したドキュメントが以下になります。（リンク）\n実際のページ: MKDocsで作成され、Swaggerドキュメントも閲覧可能 ライブラリのインストール 今回利用するライブラリは以下の4つになります。\nfastapi：API作成フレームワーク mkdocs：MKDocsのメインライブラリ mkdocs-material：生成するサイトのテーマを追加するライブラリ mkdocs-render-swagger-plugin：APIドキュメントをMKDocs上で閲覧するためのライブラリ 私が作成している環境ではpipenv を使ってライブラリ管理していますので、リポジトリでは「Pipfile」にライブラリ情報がまとまってます。\nFastAPIでSwaggerドキュメントのjsonを出力 FastAPIで作成したAPIサーバは、起動したときにSwaggerドキュメントを閲覧できます。今回はこちらをサーバを起動せずとも閲覧できるよう、サーバを起動したときにAPI情報として「openapi.json」を出力しておきます。そしてその「openapi.json」をMKDocsで閲覧していきます。\n参考にしたのはFastAPIのGitHub issueでのやり取りです。（issueへ）\n最小構成でコードを書くなら以下のようになります。各処理の内容はコメントで書いていますが、サーバ起動時にのみ動く関数を作成します。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import json from fastapi import FastAPI app = FastAPI() # サーバ起動時に発火する処理 @app.on_event(\u0026#34;startup\u0026#34;) def save_openapi_json(): # openapi定義情報の取得 openapi_data = app.openapi() # ファイル出力 with open(\u0026#34;openapi.json\u0026#34;, \u0026#34;w\u0026#34;) as file: json.dump(openapi_data, file) これで一度APIサーバを起動すると、自動的に「openapi.json」が出力されるようになります。\nMKDocsでSwaggerドキュメントを閲覧する mkdocs.ymlにプラグインを定義 MKDocsでは「mkdocs.yml」に設定内容を書き込みます。私が上記リポジトリで実際に作成した内容が以下になります。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 site_name: POMS site_author: Rakuichi copyright: Rakuichi site_dir: docs docs_dir: docsrc theme: name: material locale: ja features: - toc.integrate palette: primary: brown plugins: - search - render_swagger それぞれの設定について簡単に説明しておきます。\nsite_name, site_author, copyright：サイトの基本情報 site_dir：ビルドしたHTMLソースを入れるディレクトリ docs_dir：ビルド元になるMarkdownファイル等が入ったディレクトリ theme：デザインテーマ（詳細は「mkdocs-material」の公式ドキュメント参照） name：利用するテーマ名 locale：言語 features：利用するテーマに存在する設定 palette：カラーテーマ plugins：利用するプラグイン search：ドキュメント内検索機能 render_swagger：SwaggerUIの表示機能 プラグインの設定をするところの render_swagger によって、MKDocsで生成するサイト内でSwaggerドキュメントを表示できるようにします。\n実際にMarkdown内に埋め込む MKDocsではMarkdownがサイトのもとになります。今回「backend-swagger.md」というファイルを作成し、同階層に「openapi.json」も置いておきます。その状態で「backend-swagger.md」内に以下内容を記述します。\n!!swagger \u0026lt;対象ファイル\u0026gt;!! とすることで、Swaggerドキュメントを表示することができます。\n1 2 3 # APIドキュメント !!swagger openapi.json!! これでMKDocsでもSwaggerドキュメントが表示されるようになります。試しに閲覧する場合は以下コマンドでWebドキュメントを起動します。\n1 mkdocs serve 実際に表示されるのが、この記事の冒頭の画像のような形です。\nGitHub Pagesで公開する 簡単な説明にはなりますが、以上でページの作成はできました。あとはGitHub Pagesを利用して、作成したウェブドキュメントをmkdocs serveせずとも見れるようにしてみます。\n「mkdocs.yml」にてビルド先を指定していますので、以下コマンドを実行すると「docs」ディレクトリにHTMLやcssが出力されます。\n1 mkdocs build あとはpushし、GitHubのリポジトリ上でGitHub Pagesの公開設定を行うだけです。GitHub Pagesでは「docs」ディレクトリを対象として選択可能なので簡単に設定できるかと思います。\n参考：GitHub Pagesの公式ドキュメント\nまとめ かなり簡単な説明にはなりますが、Pythonだけでバックエンドも、フロントエンドも、ドキュメントも作ってしまうということができました。しかもGitHubですべて管理できるというのも気に入っています。\nおそらくこれがベストプラクティスというわけではないと思います。しかし、個人的にいろいろできることがありそうだなと感じており、引き続き関連要素の学習を続けていくつもりです。\n","description":"MKDocsで作成するドキュメントに、FastAPIで生成されるSwaggerを表示します","id":5,"section":"posts","tags":["Python","FastAPI","MKDocs","GitHub"],"title":"FastAPI×MKDocs（×GitHub Pages）でドキュメント生成","uri":"https://rakuichi4817.github.io/posts/poms-02/"},{"content":"今年はなんといってもいろいろな経験をした1年でした。一人暮らしを始めたことが大きなきっかけですが、仕事面でもクラウド開発に本腰を入れだしたり、公私ともに様々なことを経験できました。\nということで、振り返りと来年の目標を書いていけたらと思います。\nプライベート 初の一人暮らし 上半期の振り返りをした記事でも触れたのですが、今年から一人暮らしを始めました。ずっと実家暮らしをしてきたこともあり不安も大きかったですが、それなりにまともな生活を遅れたと思います。\n在宅勤務ということもあり、家事に時間を使いやすいということもありますが、掃除、洗濯、料理等、一通りできています。男の一人暮らしにしては部屋はきれいな方かなと。料理は凝った料理は作れないですが、週3～5回は自炊しているのでメニューも少しずつ増えている状況です。\n来年以降も継続してメニューを増やしていければと思っています。部屋も綺麗な状態をキープできれば。\n趣味 ヴィッセル ヴィッセル神戸は前半戦の不調を何とかしのぎ、残留することができました。ただ、年末に向けて選手の大量放出、パッとしない補強、チームとしての方向性が見えない状況にがっかりしています。親会社の楽天の経営不振の影響をそのまま受けているのか不明ですが、フロントにはまったく期待できません。来年のシーズンシートはいったん買わずに、期待値低めで応援していきます。\n映画は劇場で18本、サブスク合わせると75本 今年見た映画は75本でした。目標の100本には遠く及ばずといった結果で、もう少し映画館に通いたかったです。トップガンをきっかけにIMAXシアターにハマった1年でした。\n映画記録: 一番よかった映画を決めるのは難しいですが、よかった映画を10本あげておきます。\nトップガン・マーヴェリック スパイダーマン・ノー・ウェイ・ホーム ナイブズアウト グレイマン レッドノーティス ギフテッド Coda あいのうた インターン・シップ レオン マイ・インターン レオンのように昔の名作も少しずつ見ていっていますが、ネトフリ映画の勢いがすごいなと感じた1年でした。大好きな女優であるアナ・デ・アルマスの主演作である「ブロンド」は正直期待はずれでしたが\u0026hellip;。\nミュージカル・舞台・ライブ鑑賞 今年見に行ったミュージカル、舞台、ライブは以下の通りです。\nミュージカル「マイ・フェア・レディ」 ミュージカル「四月は君の嘘」 ライブ「なにわ男子 Debut Tour 2022 1st Love」 ミュージカル「ミス・サイゴン」 舞台「ハリー・ポッターと呪いの子」 ミュージカル「ジャージー・ボーイズ」 梅田芸術劇場\n赤坂ACTシアター\n新歌舞伎座\n初めてジャニーズのライブに参加したり、舞台を見に東京に行ったりとかなり楽しめました。大阪城ホールや、新歌舞伎座、赤坂ACTシアター、いろいろな劇場に行けたのもよかったです。\nジャージーボーイズに関してはCDを購入してずっとリピートしていました。もともと映画を見ていたので、映画の世界が目の前に広がっていて感動しました。生の中川晃教さんの歌声に驚いたのは今でも覚えています。自称「天使の歌声」も納得の歌声でした。\nミスサイゴンでは、市村正親さんが歌う「アメリカンドリーム」に圧倒されました。初めて見るミスサイゴンで市村正親さんの演技を見れたのは貴重な経験だと思います。\n来年もいくつか気になっているミュージカルがあるので、場所問わず足を運べたらと思います。また、いくつか見ていく中で、朝夏まなとさんと青山郁代さんが推しになりました。このお二方が出ているミュージカルを見ていきたいです。\n初のディズニー旅行 念願だった初のディズニー旅行に。行くならランドとシーの両方に行くんだと決めていたので、しっかり両方に行きました。\nアトラクションやショーを回る計画を立てていたので、1時間以内ですべてのアトラクションを回れ非常に満足しました。一番楽しみだったアトラクション、美女と野獣は期待値以上でした。一緒に乗っていたおばさま達と感動を分かち合う程（笑）。\n美女と野獣: ビースト・キャッスル ショーのマジカルミュージックワールドは抽選だったのですが、なんと最前列の席が当たり楽しむことができました。ディズニープリンセスって惚れ惚れしますね\u0026hellip;。\nマジカルミュージックワールド: シーでは、新しいショーであるビリーブの初日だったこともあり、大量の地蔵を横目にシーを楽しみました。ミッキーとダッフィーのグリーディング、初めてのソアリン等々満喫できたと思います。\n来年も行きたいですが、お金と相談です\u0026hellip;。\n仕事・技術関連 クラウド開発 仕事関連の面でいえば、目標としていたアプリ・システム開発関連の知識を少しはつけられたと思います。具体目標としていた「AWS クラウドプラクティショナー」も取得できたので、来年は「AWS ソリューションアーキテクト」でも取ろうかなと思っています。ただ、資格を取ることにあまり意味は感じていないので、実際にAWS上でいろいろ構築していきたいです。\nクラウド環境での開発をしていると、クラウドならではの設計ポイント等が出てくるので、そのあたりを理解しつつ従来の開発手法も少し知識を入れておきたいです。\nあとはプロジェクトマネジメントも体系的に学んで行く予定です。\nデバおじになる 仕事関連なのかわからないですが、今年は（も）デバイスをいろいろ買いました。年末には「Thinkpad X13 Gen3(AMD)」も買いました。メモリ32GB、SSDは後から換装して1TBにしました。さらにはゲームもできるといわれる程のAMD Ryzen™ 7 PRO 6850Uを搭載する無駄にハイスペックなPCです。せっかく買ったので、今まで以上にいろいろエンジニアリング関連の勉強もしないとな～と浅く考えています。\nx13gen13: 無駄ハイスペック ほかにもいろいろ買いました（一部貰い物）。\nロジクール MX MECHANICAL MINI（キーボード） ロジクール MX MASTER 3S（マウス） Sony WH-1000XM5（ワイヤレスヘッドフォン） Anker Soundcore Liberty 4（ワイヤレスイヤフォン） Acer Nitro XV253QXbmiiprzx（モニター） 来年は少し財布のひもを締めて行きたいですね。\n総括 あらためていろいろ経験できた1年でした。ただ、それと同時にかなりお金が飛んで行ったので、来年はお金の使いどころを厳選していきたいです。無駄なものを買わないこと、外食の頻度と料金を抑えるところからですかね。\n今年も1年ありがとうございました。\n","description":"お金は使ったけどもたくさんの経験ができた1年","id":6,"section":"posts","tags":["感想","写真"],"title":"2022年振り返りと2023年の目標","uri":"https://rakuichi4817.github.io/posts/2022-summary/"},{"content":"PythonでAPIを作成するときに使われるFastAPIですが、やはりアプリにしたいというところで、フロントエンドの部分を作るのに困っていました。手っ取り早く画面を作るには、そこまでフロントエンドの技術を持っていないので\u0026hellip;。そんな時、StreamlitというPythonで簡単にアプリが作れるフレームワークがあることを知りました。\nStreamlitは、リッチなアプリが作れる便利なフレームワークです。このフレームワークは、データを扱うアプリの作成をターゲットとしています。そのため、データ分析や機械学習系のツールを作る際に、手っ取り早くアプリ化するには、とても適していると思います。\nただ今回は、こちらのStreamlitをあくまでフロントエンド用に利用し、FastAPIで作成したAPIサーバとやり取りさせることで、Pythonだけでバックエンドとフロントエンドを分離したアプリを作成していきます。\n実際に作成してしているアプリの紹介 こちらの内容に関しては記事執筆時点（2022年10月7日）のものなので、リポジトリの内容とずれがあるかもしれません。 ↓リポジトリ\n練習で作成しているアプリの画面です。\n足し算機能: 単純なGetリクエスト モザイク処理: 画像データのやり取り 本記事では足し算機能についてのみ紹介いたします。 今後も様々な機能を、練習として実装していこうと思っています（機能毎の記事も書くかもしれません）。\n作成中のアプリでは以下のようなプロジェクト構成をしています。マイクロサービスというならPipfileも分けるべきなのですが、開発の簡略化のためにまとめています。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 poms ├─.vscode VSCode開発用設定 │ settings.json ├─backend バックエンド（FastAPI）ソース │ │ main.py アプリ立ち上げ用 │ │ __init__.py │ ├─config バックエンドの設定関連 │ ├─libs バックエンドのロジック部分 │ ├─schemas Pydanticモデル定義 │ └─v1 API作成部分 │ │ api.py │ │ __init__.py │ └─routers エンドポイント定義 ├─docs 全般のドキュメント └─frontend フロントエンド（Streamlit）ソース │ │ home.py 立ち上げ用（ホーム画面） │ │ __init__.py │ ├─config フロントの設定関連 │ └─pages フロントの各ページ ├─Pipfile ├─Pipfile.lock └─README.md なお、以下の説明では、上記のプロジェクト構成は利用せずにシンプルな形で説明しています。\n足し算機能を作成してみる 非常に単純な足し算機能を作成してみます。役割分担としては以下のようになります。\nStreamlit（フロントエンド） aとb、2つのクエリパラメータ（数値）の入力 バックエンドへの足し算処理リクエスト レスポンスを受け取って表示 FastAPI（バックエンド） 足し算エンドポイントの作成 記事内ではソースを簡略化していますので、実際の実装を見たい方はリポジトリをご参照ください。\n繰り返しになりますが、以下のコードは上記のプロジェクト構成に依存していません。記事内ではコードを簡略化していますので、実際の実装を見たい方はリポジトリをご参照ください。 フロントエンド部分 APIへのリクエストはrequestsライブラリを利用します。ボタンを用意して、そのボタンがクリックされたらif submitted内の処理が走り、リクエストが実行されます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import requests import streamlit as st with st.form(\u0026#34;get_sample_form\u0026#34;): # リクエスト先 endpoint_url = \u0026#34;http://127.0.0.1:8000/plus\u0026#34; # 表示と入力 st.write(\u0026#34;## 足し算（a + b）\u0026#34;) st.write(\u0026#34;Getリクエスト（クエリ付き）\u0026#34;) a = st.number_input(\u0026#34;a を入れてください\u0026#34;) b = st.number_input(\u0026#34;b を入れてください\u0026#34;) # 計算実行ボタン submitted = st.form_submit_button(\u0026#34;計算する\u0026#34;) if submitted: # ボタン押下時の処理 response = requests.get(endpoint_url, params={\u0026#34;a\u0026#34;: a, \u0026#34;b\u0026#34;: b}) if response.status_code == 200: result = response.json()[\u0026#34;result\u0026#34;] st.success(f\u0026#34;**{result}**\u0026#34;) else: st.error(f\u0026#34;{response.status_code}エラーが発生しました。詳細は以下を参照ください\u0026#34;) st.json(response.json()) Streamlitは公式ドキュメントが充実しているので、ボタンや入力欄の作成はそちらを見てください。処理の流れとしては、受け取った入力をrequestsでGetリクエストするだけです。st.number_input()を利用しているので、数値以外は入力できません。また、デフォルトで0がはいっているため、中身がないままリクエストされることもありません。\nバックエンド部分 今回、Python3.10を利用しているので、型ヒントの書き方がPython3.9までとは違う点に注意が必要です。Python3.9までの方はint | floatとなっている部分を、Union[int, float]としてください（from typing import Union）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 from fastapi import FastAPI, Query from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel, Field class AddIn(BaseModel): \u0026#34;\u0026#34;\u0026#34;GET /plus の入力\u0026#34;\u0026#34;\u0026#34; a: int | float = Field(Query(description=\u0026#34;足される数\u0026#34;)) b: int | float = Field(Query(description=\u0026#34;足される数\u0026#34;)) class AddOut(BaseModel): \u0026#34;\u0026#34;\u0026#34;GET /plus の出力\u0026#34;\u0026#34;\u0026#34; result: int | float = Field(description=\u0026#34;足し算の結果\u0026#34;) app = FastAPI() # CORS設定（公式ドキュメント：https://fastapi.tiangolo.com/ja/tutorial/cors/） app.add_middleware( CORSMiddleware, allow_origins=[\u0026#34;http://localhost\u0026#34;, \u0026#34;http://localhost:8501\u0026#34;], allow_credentials=True, allow_methods=[\u0026#34;*\u0026#34;], allow_headers=[\u0026#34;*\u0026#34;], ) @app.get(\u0026#34;/plus\u0026#34;, response_model=samples.AddOut) async def add(query: samples.AddIn = Depends()): \u0026#34;\u0026#34;\u0026#34;足し算 Parameters ---------- a : int | float 足される数\\\\ b : int | float 足す数 \u0026#34;\u0026#34;\u0026#34; return {\u0026#34;result\u0026#34;: query.a + query.b} CORSの設定をしておかないと、8501ポートで開いているStreamlitからのリクエストを遮断する可能性があります。この辺りは公式ドキュメントをご覧ください\n公式ドキュメント：CORS (オリジン間リソース共有) - FastAPI\n実行画面 フロントエンドとバックエンドをそれぞれ立ちあげて、アプリ画面からリクエストを実行してみます。\n足し算機能: -20\u0026#43;40=20 計算結果を表示できました。\nまとめ StreamlitとFastAPIを使うことで、Pythonのみでも簡単にフロントエンドとバックエンドを分離したアプリを作成することができました。フロントにややこしい処理を実装する必要がないため、プログラムの管理もしやすかったです。また、React等を学んで、フロントのみ切り替えることも簡単なので、まずアプリを作るという点では非常に使いやすいですね。\n今後は、上で紹介したモザイク機能に関する記事や、その他の機能を実装していこうかなと思っています。\n","description":"FastAPIとStreamlitを用いて、Pythonだけでバックエンドとフロントエンドの両方を作ります。","id":7,"section":"posts","tags":["Python","FastAPI","Pydantic","Streamlit"],"title":"FastAPI×Streamlitでアプリ開発（Getリクエスト）","uri":"https://rakuichi4817.github.io/posts/poms-01/"},{"content":"タイトルの通り、FastAPIで自動生成されるOpenAPIドキュメント（Swagger）内で、Pydanticで定義したクラスをDependsしたクエリパラメータに対して、情報（説明文）をつける方法について紹介します。\n※途中で触れますが、今回の解決方法はその場しのぎ的で奇麗な形ではありません\nこれからの説明では、単純にクエリパラメータとして受け取った文字列（名前）を、挨拶文にして返すAPIを例に見ていきます。（「Taro」を受け取って「Hello Taro!」を返す）\n※手っ取り早く実装例を見に行く\nPydanticモデルを利用しない場合 Pydanticを利用せずにFastAPIのみで完結させる場合は、簡単にドキュメントへ説明文を反映させることができます。\nシンプルな定義 まずは、最低限の実装で確認してみます。こちらの方法では、ドキュメントに説明文をつけることはできません。\n1 2 3 4 5 6 7 8 from fastapi import FastAPI app = FastAPI() @app.get(\u0026#34;/hello\u0026#34;) async def hello(name: str): return {\u0026#34;message\u0026#34;: f\u0026#34;Hello {name}!\u0026#34;} この状態でドキュメントを確認してみます。説明文はありません。変数名で伝わるので、必要ないと考えることもできます。\nクエリパラメータのドキュメント1: シンプルな定義 Queryを使った定義 fastapiからQueryをインポートして、クエリパラメータの説明を加えていきます。Queryは様々なパラメータを持っており、制約（文字数制限等）を加えることもできます。今回は、あくまでドキュメントに情報を加えるだけなので、制約などについては触れません。詳しく見たい方は公式ドキュメントをご覧ください。\n公式ドキュメント：https://fastapi.tiangolo.com/ja/tutorial/query-params-str-validations/\nOpenAPIドキュメントに、対象クエリにどのようなものを入れるのか、説明を加えたいと思います。\n1 2 3 4 5 6 7 8 9 from fastapi import FastAPI, Query app = FastAPI() @app.get(\u0026#34;/hello\u0026#34;) async def hello(name: str = Query(description=\u0026#34;名前を入れてください\u0026#34;)): return {\u0026#34;message\u0026#34;: f\u0026#34;Hello {name}!\u0026#34;} ドキュメントを見てみましょう。\nクエリパラメータのドキュメント2: Queryを使った定義 descriptionを加えることでドキュメントに説明が記載されました。\nPydanticを利用する場合 FastAPIでPydanticモデルを使用する時は、基本的にリクエストボディのデータを定義する場合になります。公式ドキュメントでは以下のように書かれています。\nリクエスト ボディを宣言するために Pydantic モデルを使用します。そして、その全てのパワーとメリットを利用します。\nhttps://fastapi.tiangolo.com/ja/tutorial/body/\nクエリパラメータにPydanticモデルを適応する場合は、Depends()を利用します。こちらの方法はQiitaでも共有されています。\nFastAPIでクエリパラメータの指定にPydanticのModelを使う - Qiita\n今回の例では以下のようになります。引数queryにHelloInオブジェクトが代入されるので、受け取った文字列を利用する場合はquery.nameとします。\nHelloIn内に複数の変数を定義することで、複数のクエリを受け取ることも可能です。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from fastapi import Depends, FastAPI from pydantic import BaseModel app = FastAPI() class HelloIn(BaseModel): name: str @app.get(\u0026#34;/hello\u0026#34;) async def hello(query: HelloIn = Depends()): return {\u0026#34;message\u0026#34;: f\u0026#34;Hello {query.name}!\u0026#34;} この場合のドキュメントは以下のようになります。\nクエリパラメータのドキュメント3: Pydanticを用いた定義 続いてPydanticを使いつつ、ドキュメントに説明文を反映していきたいと思います。感覚的には、HelloIn内のname: strをname: str = Query(description=\u0026quot;名前を入れてください\u0026quot;)にすれば良い気がしたのですが、これはうまく反映されませんでした。\nこちらに関して調べていたところ、FastAPIのリポジトリにイシューがあがっていました↓\nQuery parameters from Depends do not show description in docs · Issue #4700 · tiangolo/fastapi\n今回紹介する方法はこのイシュー内でコメントされている方法になりますが、「I think there should be a better solution for this issue（この問題に対するより良い解決策があるはずです）」と書かれているので、他にいい方法があるかもしれません。\n対処としては、以下のようにFieldやQueryで2重にすれば良いです。ただ、issueを見ていても「やってみたらうまくいきました！」という書き方なので、TIPS的な認識で利用しています。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from fastapi import Depends, FastAPI, Query from pydantic import BaseModel, Field app = FastAPI() class HelloIn(BaseModel): name: str = Field(Query(description=\u0026#34;名前を入れてください\u0026#34;)) # FieldでなくてQueryでもよい↓ # name: str = Query(Query(description=\u0026#34;名前を入れてください\u0026#34;)) @app.get(\u0026#34;/hello\u0026#34;) async def hello(query: HelloIn = Depends()): return {\u0026#34;message\u0026#34;: f\u0026#34;Hello {query.name}!\u0026#34;} 以下のように、ドキュメントに説明文が反映されています。\nクエリパラメータのドキュメント4: Pydanticを利用してドキュメントにも反映 ","description":"Pydanticで定義したモデルを、FastAPIのクエリパラメータとしてDependsしたときに、自動生成されるOpenAPIに詳細情報（説明文）を表示させる方法。","id":8,"section":"posts","tags":["Python","FastAPI","Pydantic"],"title":"Pydanticで定義したクエリパラメータをFastAPIのドキュメントに反映する","uri":"https://rakuichi4817.github.io/posts/fastapi-tips-01/"},{"content":"研究室時代からSlackを利用してコミュニケーションをとって来ました。就職してからも環境に合わせて様々なチャットツールを利用しています。もちろん私生活でもチャットを使うことは日常になっているかと思います。\n今までは特に意識していませんでしたが、最近このチャット型のメッセージにおける読みやすさについて考えていました。そもそもの文章の書き方について意識しておく点も多いと思います。ただ、今回はチャット特有の書き方について、私が考える読みやすいチャットの書き方をまとめたいと思います。\nあくまで私の意見になるので、もっとこうしたほうが読みやすい等の意見があれば、右下のチャットボタンよりコメントお願いいたします。\nメールとチャットではテキストを見る環境が違う 私が考える、読みやすいチャットメッセージを書くために重要なポイントは次の2つです。\n①少なくとも1文中には改行を入れない\n②2、3文ないしは1文でもある程度の長さで段落を変える\n①に関しては、特にメールと比べた場合のチャットの書き方なのかなと思います。\n従来のコミュニケーションツールであったメールの書き方を以下の例で確認していきましょう\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ヴィッセル神戸 担当者様 お世話になっております。 ヴィッセル神戸サポーターのRakuichiです。 この度はJ1リーグ最下位という厳しい状況の中、 飯野選手という素晴らしい選手を補強いただき、 誠にありがとうございます。 守備構築を狙って就任させたロティーナ監督を、 たった数か月で解任したことは驚きました。 フロントに対する不信感が、サポーターの中で 確実に募っているとは思います。 しかし、そうはいっても応援するしかないので、 一致団結してトモニ闘いましょう！ We Are Kobe! （内容は置いておいて）よく見るメール文書の形なのではないかと思います。要するに、一定の文字数になったら切りのいいところで、文の途中でも改行をするという書き方です。\n基本的には読点や助詞のタイミングで改行することが多いと思いますが、中には一定の文字数になったら絶対改行するといった人もいるかもしれません。以下の記事でも、大体20~30文字程度での改行を推奨しています。\n確かにメールで改行のない長い文を送られると読みにくいと感じると思います。\nただ。チャットに関しては、改行を入れることで逆に見にくくなることが考えられます。PCはもちろんスマホやタブレットなど、様々なデバイスでチャットアプリを見るようになった今、受け取り側のテキスト表示幅は想定不可能です。\n特にチャットツールの性質上、ツール上にメッセージ以外の情報も多く含まれています。そのため、チャットツールとしては広く表示していても、メッセージの表示幅は狭いということも考えられるでしょう。\nでは実際に、チャットにおいてメールと同じ風に文に改行を入れているとどうなるか、Slackの場合で見ていきましょう。\nメールのように書く\n明らかに読みにくいです。表示幅がチャット送信者の想定以上に小さかったため、意図せぬところで改行が入り余計に読みにくくなっています。もちろんメールでも同じことが言えるかもしれませんが、チャットは特にこの傾向が強いと私は思います。\n1文中に改行を入れない では、私の思うポイント①の「少なくとも1文中には改行を入れない」を実践して、再度どのような形になるか確認しましょう\n1 2 3 4 5 6 7 8 9 10 11 12 ヴィッセル神戸 担当者様 お世話になっております。 ヴィッセル神戸サポーターのRakuichiです。 この度はJ1リーグ最下位という厳しい状況の中、飯野選手という素晴らしい選手を補強いただき、誠にありがとうございます。 守備構築を狙って就任させたロティーナ監督を、たった数か月で解任したことは驚きました。 フロントに対する不信感が、サポーターの中で確実に募っているとは思います。 しかし、そうはいっても応援するしかないので、一致団結してトモニ闘いましょう！ We Are Kobe! まずは①に従って、少なくとも1文は改行せずにつなげるようにして、その他の改行はそのままにしました。\nこの状態でもう一度、先ほどと同じ幅のSlackでどのように表示されるか確認しましょう。\nポイント①\nいかかでしょうか。読みやすくなったと思いませんか？文中には改行を入れていないので、単語の途中で改行が入ってしまってはいます。しかし、意図せぬ改行が入ることに比べれれば、読みやすいと私は思います。\n2、3文ないしは1文でもある程度の長さで段落を変える 続いてのポイントである「2、3文ないしは1文でもある程度の長さで段落を変える」について見ていきましょう。\nこちらはWeb文書の書き方などを参考にしたものになります。なぜ参考にしたかというと、チャットの受け取り手の表示環境が一定じゃないという状況が、Webページと同様だからです。\n参考にしたWeb文書の書き方は以下のページになります。\nこちらで触れられているWeb文書の書き方について、一部抜粋させていただきます。\nWeb文章においては改段を用いることで段落間にスペースを確保し、段落の区切りを明示する方法が読みやすいとされています。\n確かにスマホでニュースアプリなどを見ていても、通常の文書に比べて多くの段落の区切りが存在しています。通常の文書の段落はある程度の意味のまとまりで変えますが、Web文書の場合はある程度の文字数で段落を変えるべきということになります。\n私のこの記事もWeb文書の書き方を参考にしつつ作成しているので、通常の文書以上の段落変更があると思います。\nでは、先ほどのチャットメッセージをこの原則にも従って書き直してみます。なお、Slack上では1行空白を空けることで、段落が替わります（他のチャットツールもおおよそ同じ）。\n1 2 3 4 5 6 7 8 9 10 11 12 ヴィッセル神戸 担当者様 お世話になっております。 ヴィッセル神戸サポーターのRakuichiです。 この度はJ1リーグ最下位という厳しい状況の中、飯野選手という素晴らしい選手を補強いただき、誠にありがとうございます。 守備構築を狙って就任させたロティーナ監督を、たった数か月で解任したことは驚きました。フロントに対する不信感が、サポーターの中で確実に募っているとは思います。 しかし、そうはいっても応援するしかないので、一致団結してトモニ闘いましょう！ We Are Kobe! では、早速Slack上で確認してみましょう。\nポイント①、②\nいかかでしょうか？かなり読みやすくなったと思いませんか？\n改めて、3つの状態を並べてみます。\nメールのように書く\nポイント①\nポイント①、②\nまとめ 今回はチャットの読みやすい書き方について検討しました。個人的には今回紹介した書き方をしばらく実践していこうと思います。\nもちろん、今回紹介した方法でチャットを作成すると、チャットアプリを横に長くしたときに、文字が横に長くなってしまうデメリットはあります。しかし、このデメリットより紹介したメリットを取ろうと思います。\nこの記事を読んでくださった方で、「こんなのはどう？」というのがあればぜひコメントください。\n","description":"読みやすいチャットの書き方について個人的なポイントを紹介します","id":9,"section":"posts","tags":["Web","Work","Writing"],"title":"チャットはメールのように文中で改行すべきではないと思う","uri":"https://rakuichi4817.github.io/posts/chat-messages/"},{"content":"前回の記事「2022年上半期振り返りと下半期に向けて（仕事・技術編）」に続いて、趣味の振り返りもしていこうと思います。\n仕事・技術的な面 ヴィッセル神戸←本記事の内容 映画・観劇←本記事の内容 その他←本記事の内容 ヴィッセル神戸の上半期はボロボロ\u0026hellip; 個人的上半期MVP: 24:酒井高徳 今期のヴィッセルは本当にボロボロです\u0026hellip;。前半戦17試合を終えてたったの2勝。当然の最下位で、試合の内容もチーム状況も最悪という暗黒状態。私の推しメン、サンペールは今季絶望のけがをするという。\nコロナも多少落ち着いてきて、シーズンシートも購入し、スタジアムに行きやすい場所で一人暮らしを始めたのに悲しい限りです。負けるにつれて重い雰囲気になるスタジアムもつらいです。\n個人的には三浦監督（2020年の後半から今季序盤まで指揮）懐疑派だったので、「ほら見たことか」という状況ですが。昨季3位だったからと言って、戦略のない監督を継続したフロントの責任だと思っています。しかも、守備の構築に期待して再建を託したロティーナ監督を数か月で「守備的すぎる」と言って解任したという。\nフロントがどういう考えで人事をしているのかわかりませんが、選手補強といい場当たり的な感じなんですよね。中長期戦略ゼロ、資金はあるのにコスパは悪い印象です。能力のある選手（昨季ならフェルマーレン）に依存して、抜けてしまったら崩壊するという悪い職場の典型みたいな状況です。\n私のようなサッカー素人からすると、なぜあれだけ良い選手を集めて勝てないのか不思議です。もちろん、チームスポーツだからというのあると思いますが、サガン鳥栖なんかは毎シーズン主力を引き抜かれてもチームとして戦っていますから。\n良い選手を集めているといっても、ほんとに必要なポジションの補強ができていなかったりするのでどうかと思いますが。どれだけ有能な部下がいても、マネジメント層がダメだと組織としてはダメという感じなのでしょうか。\nとはいっても、私は選手を応援するだけです。試合の勝ち負けにかかわらず、熱く味方に話しかける酒井高徳選手には感動を覚えます。明らかに今季一番チームに貢献している選手ですし、サポーターに対しての思いも伝わってきます。試合中のプレー1つ1つに気迫を感じ、判断やテクニックにも目を引き付けられます。\n後半戦は3回目の監督就任となる吉田監督とJ1残留を目指すことになりましたが、ホームの試合は変わらず現地に見に行こうと思います。もう今は戦略どうのこうの言ってられませんしね。\n初めて代表戦を観戦 代表の古橋: ノエビアスタジアムにて ヴィッセルはボロボロですが、ヴィッセルから世界（セルティック）へと羽ばたいた古橋は絶好調。初の海外挑戦でゴールを量産し、熱狂的なスコットランドサポーターからも愛される存在となっている古橋。その古橋が代表入り、日本代表として神戸で開催される試合にやってくる！「これは行くしかない」と思い、初めての代表戦の観戦へ。\n普段はヴィッセルサポーターでいっぱい（？）のノエビアスタジアムも、代表ユニホームに身を包んだ方であふれかえり、いつもと違う光景が楽しかったです。試合中、普段のJリーグでは反応が起きないようなちょっとしたプレーでお客さんの反応があり、代表戦らしさを感じました。\n雰囲気はよかったです。久しぶりに会った高校の友人たちとサッカー観戦できたことも素晴らしかったです。しかし、\n古橋を出さんかい！森保！\nここ神戸やぞ！？有観客状態初の凱旋試合やぞ！？ という感想です。対戦相手が特別すごいわけではないですし、私の楽しみは代表で輝くセルティック所属のKyogoが日の丸を背負って戦う姿だったんです。ところが、１分たりとも出場させないという謎の逆張り。私の周りにも古橋のユニフォームを着て応援している人が多く、そういった観客の期待を裏切る森保に怒りしかありませんでした。\nエンターテイメントとしても全くダメで、最近の日本代表の戦い方自体も個の力に頼ったサッカーなので、代表人気の低迷も納得かなぁと。今年はW杯があるので楽しみですが、どういう戦い方になるのか楽しみです。というかこのまま森保で行くかが気になります。\n上半期で見た映画は39本 劇場で見た映画: トップガンは2回劇場に ヴィッセルと同じくらいの趣味として、映画鑑賞があります。今年の上半期は初めての一人暮らしを始めるというビックイベントがあり、あまり数は見れなかったです。Prime VideoにもDisney+にも見たいものはたくさんあるのですが。ただ、映画館に行く回数が増えたので満足はしています。それでも上半期で9回なので、下半期はもう少し増やしたいです。\n最近は、音・音楽や映像に特徴がある作品に関しては、IMAXシアターのようなちょっと特別な劇場で見るようにしています。今まではあまり気にしていなかったのですが、せっかく映画館に行くわけですし良い環境で聞きたいので。そのきっかけになったのは、話題の「トップガン・マーヴェリック」です。\n西宮IMAXシアター\n姫路4DXScreen\nもともと見に行くつもりだったのですが、先に見に行った友人から「できるならIMAXで見たほうが良い！」と言われIMAXで鑑賞。エンジン音が体の芯まで響く感じがして、臨場感のすごさに感動しました。ドッグファイトシーンの緊張感、迫力それらのすべてが、普段見に行く映画館とは比べ物になりませんでした。\n大満足して映画の趣味に合う後輩に連絡したところ「姫路でやっている4DXScreenエクストリーム上映はもっとすごいらしい」と言われ、「もうこれは行くしかない」とその後輩と共に2回目のトップガンマーヴェリックの世界へ。\n4DXScreenは次のような劇場のことを指します。\n「4DX SCREEN」シアターは、体感型アトラクションシアター「4DX」と、3面マルチプロジェクション上映システム「ScreenX」が融合した体感型シアターです。革新的なスペシャルエフェクトと、視野270度の3面マルチプロジェクション上映システムによって、今までにないダイナミックな映画体験をご提供します。\n引用元：https://www.cinemasunshine.co.jp/4dx-screen/about/\nさらに、エクストリーム上映というのは、4DXのシートモーションレベルを最大にしているものになります。要するするに動きが普通の4DXより激しいということです。あまりにも激しすぎて、周辺店舗への影響から夜にしか上映できないとの噂も。\n期待値マックスで見に行った感想は、\n極上の映画体験！\nドッグファイトシーンだけでもアトラクション化してほしい！\nドッグファイトシーンの没入感は単なるIMAXシアターの比ではありません。機体を急上昇させるシーンでは当然座席も上に傾き、まるで自分にもGがかかっているような感覚を覚えます。パイロットたちが機体を傾ければ、それに応じて自分たちも傾く。さらに、機銃を打たれるシーンでは空気砲のようなものが飛んできますし、270度の液晶でドッグファイトシーンを余すことなく楽しむことができます。\nエクストリーム上映というだけあり、あまりの激しさに座席からずり落ちそうになるレベルでした。4DXはアベンジャーズ1作目以来でしたが、トップガンマーヴェリック程4DXで見るべき作品はあまりないと思います。戦闘機に乗り込むマーヴェリック達の感覚を共有できる感じが最高でした。\n全国でも数少ない4DXScreenエクストリーム上映を姫路で見ることができるので、兵庫県民はぜひ見に行ってほしいです。\n舞台の世界へ 映画に加え、今年からは舞台鑑賞も本格的に始めました。昨年もいろいろ見に行くつもりでしたが、コロナですべて流れてしまったので、一人で鑑賞しに行くのは今年からとなりました。\nマイフェアレディ、朝夏まなとさんの虜に 記念すべき一発目が、梅芸で鑑賞した「マイフェアレディ」でした。映画好きであれば名前は聞いたことがある名作ミュージカルです。あらすじは知っているものの、恥ずかしながら映画は見たことがなかったです。舞台に関しても、大地真央さんが昔にイライザを演じていことをうっすら知っている程度の知識でした。\n初めての梅芸: 思わずパンフ購入 私でも知っているタイトルで、素晴らしいと聞く梅芸での公演なのだから見るしかないと考え、奮発してS席を購入。基本的にはラブストーリーですので、女性が多いのは覚悟していました。男1人はかなり少数派なのだろうなと感じながら、人生初の梅芸に向かうと、やはり女性が多く少し緊張しました。\nそれでも、座席に座ってしまえばあまり気になりませんでした。後ろが通路だったこともあり、後ろの方の視界を遮る心配がなかったのもよかったです。加えて、開演前に隣に座っていらっしゃった40代か50代くらいの女性とその方のお母さまが話しかけてくださって、とてもリラックスることができました。\n1部と2部の間にも少しお話させてもらったのですが、お母さまは昔から舞台のマイフェアレディを見ていたそうで、自分が見ていた作品を娘さんと見に来れるって幸せだろうなと感じました。あの時話しかけてくださった方々、ありがとうございました。\n舞台を見た感想としては、再演する際はぜひもう一度見たいと思いました。とても大好きな好きな作品になりました。登場人物がみな魅力的なので、収支楽しめました。また、基本的に明るめの曲が好きなこともあり、マイフェアレディの楽曲がとても気に入りました。いまでもサントラを聞いているくらいです。\nさらに、朝夏まなとさんの魅力をビシバシ感じました。まずは圧倒的歌唱力。踊りながらあれだけの心に残る歌を歌えるなんて\u0026hellip;。そして、ちょっとした所作にほれぼれしてしまいました。1階席でしたが、比較的後ろの列で顔までははっきり見えませんでした。しかし、その時の心情を丁寧に表現しつつ、離れた客席でも伝わる動きに感動してしまいました。圧倒的な存在感でした。\n舞台「四月は君の嘘」 大満足のマイフェアレディ鑑賞を終え、次の舞台鑑賞は四月は君の嘘でした。君嘘は大学時代にドはまりした漫画・アニメで、人生で一番好きといっても過言ではない物語です。\nアニメのフィナーレイベントのパンフと舞台のパンフ: 原作が好きすぎて実写映画は見ていませんでした。それでも舞台が兵庫に来るのであればぜひ見に行こうと思い見に行きました。2，3時間の舞台にどうやって落とし込むのだろうかと思っていましたが、きれいにまとまっていたと思います。原作厨でも満足できました。椿や相座、井川さんの描写が少なかったのは残念ですが。時間の都合上仕方がないですよね。\n満足ポイントとしては、生田さんの宮園かをりが想像以上にはまっていたことです。自由奔放な明るい部分と、抱えている暗い気持ちを見事に表現していました。アニメの声優していたのかな？と思ってしまうほどです。友人Aを代役に任命するシーンを生で見れたのは感動でした。\nもちろん楽曲も世界観とマッチしていました。原作では最後まで分からないかをりちゃんの本当の感情が、各シーンで歌にのせて表現されるのは新鮮でした。コロナで公演中止になっていましたが、再演されて良かったと思います。作中でもありますが、躓いてしまっても「again」ですね。\nその他とまとめ ほかにもいろいろ経験できた上半期でした。温泉旅行に行ってみたり、ジャズバーに行ってみたり。ジャズバーは完全にはまってしまったので、定期的に行きたいと思います。\n一人暮らしを始めたことで、料理をする機会が増えました。それなりに食べられる料理を作れているので良かったです（笑）。掃除洗濯も今のところ苦ではないです。男の一人暮らしにしてはまとまった部屋なのかなとは思います。\nヴィッセルの状況以外はそれなりに充実していた上半期でした。下半期はすでに楽しみにしている舞台がいくつかあります。\nハリーポッター←チケット確保済 ミスサイゴン←チケット確保済 ジャージーボーイズ ヘアスプレー ほかにも、モダンミリーや天使にラブソングをといった、朝夏まなとさんが出ている作品も気になります。ただ、ヴィッセルも映画も舞台もとなると、お金がどんどん飛んでいくのでこの辺りは財布と相談しながらになりそうです。ヴィッセルがACLで勝ち進んだら遠征もしたいですしね！！！\nそんなこんなでいろいろ書いていると、それなりの分量の記事をかけたと思います。今後継続してこれができるかはわかりませんが。今回はこの辺にしてさようなら～。\n","description":"ヴィッセル神戸の上半期はひどすぎる。一方映画や舞台鑑賞は充実（スパイダーマン、トップガン、舞台マイフェアレディ等々）","id":10,"section":"posts","tags":["感想","写真"],"title":"2022年上半期振り返りと下半期に向けて（趣味編）","uri":"https://rakuichi4817.github.io/posts/2022-second-half-summary/"},{"content":"2022年も気づけば上半期が終了しびっくりしております。ブログの更新頻度をあげると言っていたのですが、なかなかネタが思いつかず\u0026hellip;。言い訳をするなら、会社で技術ブログ的なものを立ち上げて、いろいろ記事を作成しているのが原因です。\n個人的に書いている日記は比較的継続できているので、ブログの更新も小さいネタからやっていければとは思います。ということで、上半期の振り返りと下半期に向けての目標的なものを書いていきます。\nトピックとしては、2回に分けて以下の4つを取り上げようと思います。\n仕事・技術的な面←本記事の内容 ヴィッセル神戸 映画・観劇 その他 今回はちょっと真面目寄りの話ということで、「仕事・技術的な面」について書きます。\n上半期振り返り 開発力強化期間 上半期は、かなり 「システム・アプリ開発力」 にこだわった期間でした。\n入社してからも、データ分析であったり研究開発的なことが多く、アプリやシステムとして堅牢なものを作る（コードを書く）というのは求められていませんでした。\nしかし、ちょっとしたアプリなどを作る過程で、プロジェクトファイル構成から始まり、コーディング規約、クラス設計などの開発ノウハウを強く意識するようになりました。気になることが増えてきて、調べていくとどんどん知ることが出てきて、といった流れです。\n基本的にはPython関連の知識習得が多かったのですが、最近はJavaScriptの学習や、AWSの資格取得に向けた学習も少しずつ始めています。\n加えて「開発の効率化」も意識して学習しています。自動テスト（pytest）によるテスト駆動開発や、GitHubを使ったコード・開発管理を中心に学んでいます。テストコードを書く習慣をつけることで、テストコードがないプロジェクトが信じられないレベルにはなってきました（笑）。\nとはいっても、知識だけ入れても仕方がないですし（そもそも座学が嫌いなのもあり）、実戦経験の場が欲しくなりました。そこで、会社のコミュニティを活用して数名でのマイクロサービスアプリ開発に挑戦しています。\n暗中模索のマイクロサービス開発実践 そのコミュニティでは、モダンな開発手法に慣れましょう、学びましょうというのを1つのコンセプトとして活動しています。\nDockerで開発環境も含めた環境構築を行い、フロントはReact、バックエンドはFastAPI（Python）。テストコードをpytestで作成し、GitHub、TravisCIを使って自動テストを実施。開発の管理自体もGitHubの機能で完結させています。\n今までは、個人的に使うコードを少しGitHubで管理する程度でした。今回、複数人で開発をする場を作成したことで、とてもたくさんのことを学べています。ブランチ運用やイシューの作り方、プルリクエストの運用など、座学だけでは考えられないことがわかってくるようになりました。\nコミュニティでは使い方を教える立場ということもあり、暗中模索で進めているところもあります。しかし、有名なOSSのリポジトリを参考にしたり、自分たちなりの解決案を考える過程が良い経験だなと思います。最近はリポジトリページの情報が潤ってきているので、それを見てにこにこしてます。\nとにかくナレッジシェア 個人的にはいろいろ学習しているので、ナレッジシェアの意識も強めています。「社内でこういうことを勉強してる人がいるんだよ」というアピールもこめてですが、どなたかの役に立てればうれしいですしね。また、よく言いますが、アウトプットしようとすると情報の整理にもつながるので。\nただ、ナレッジシェアの仕方も難しいと感じ出しています。「業務が忙しい中で新しい知識をインプットするのは大変だ」という方が大半、というのが現実だと思います。できるだけローコストで閲覧できるようにしないといけないと感じています。\n今までコミュニティ活動などのナレッジシェアは、ファイル共有サービスを使ったファイル共有が一般的でした。しかし、わざわざファイルを探しに行く労力、いざ見ようと思ったときに見失うという問題があると思います。\nですので、最近はドキュメントをWebページ化して閲覧しやすくしたり、社内チャットツールを積極的に使うようにしています。チャットツールに関しては、発言する方が限定されるというのが悩みどころですが\u0026hellip;。やるだけやってダメな方法は即切っていこうと思います。\n下半期に向けて いろいろ学習してきたかな？と思える上半期でした。基本的には今の活動を継続するつもりなのですが、下半期の大きな目標の1つは「AWSクラウドプラクティショナー」の取得です。\n上半期あまりできなかったことに、AWSの学習があります。今はUdemyなどを活用して学習を進めていますが、思ったより進捗がよくないので反省です。あまり資格取得は好きじゃないのですが、AWS系の資格は取る価値があるものだと思っているので頑張りたいです。\n個人的に今後のキャリアとして、アーキテクトに興味が出てきているのもあり、土台であるクラウドの知識は増やしていきたいです。\nもう1つの目標は、個人で適当なアプリを一つ作りたいです。昔チャットボットを作っていたのですが、そんな感じで何か適当なものを作れたらと思っています。\n次回 次回は、もう少し緩い日常の内容について触れていきたいと思います。ヴィッセルの状況がひどすぎて、ゆるくなるかわかりませんが\u0026hellip;\n","description":"仕事・技術関連の2022年上半期振り返りと下半期に向けてを書いていきます","id":11,"section":"posts","tags":["感想","Work"],"title":"2022年上半期振り返りと下半期に向けて（仕事・技術編）","uri":"https://rakuichi4817.github.io/posts/2022-first-half-summary/"},{"content":"この4月からひとり暮らしを始めました。初めてのひとり暮らしでしたが、部屋探しの際にネット環境も重視して今の部屋を選んだので、そのあたりのことも書きつつ、結果的に現在利用している「J:COM NET 1GBコース」の感想を書こうと思います。\nJ:COMを実際に使ってみて 感想 部屋選びの際の話などは後回しにして、先に現在利用している「J:COM NET 1GBコース」の感想を書きます。\n結論から言うと、かなり満足しています。\n在宅ワークや高画質の動画鑑賞でも遅いと感じたことがない APEXなどのオンラインゲームも、よほど高いレベルでのこだわりがなければ問題なし 混雑しやすい夜の時間でも問題なく使える と、このように全く問題なく使えています。私は仕事でデータ分析的なこともしていますので、それなりの容量のデータをダウンロード、アップロードすることがあります。しかし不便を感じることなく使えています。また、趣味でサブスクの映画を見ることも多いのですが、Disney+やPrime Videoで高画質（4K）動画を見ていても止まったりすることはありません。\nAPEXなどのオンラインゲームでも問題なく遊べています（ランクでダイアに行ける程度）。ただしpingに関しては30~50くらいになるので、高いレベルでのこだわりがある方は難しいと思います。格闘ゲームなどもきついかもしれませんが、したことがないので正確なことは伝えられません。\nネットスピードテストの結果 ネットスピードテストした結果を載せてみます。なお、私が契約している 「J:COM NET 1GBコース」は下りが1GB上限、上りが100MB上限 となっています。\nまずは、昼間の時間帯にスマホ（iPhone11）で測定した結果になります。上り、下りともに上限に近い速度が出ており、普通にネットを使う分には十分すぎる速度が出ています。\n12時頃の測定結果（スマホ）: 続いて、比較的速度が低下しやすい夜の時間帯にPCで測定した結果になります。夜間でも150Mbps出ているので十分かと思います。\n20時頃の測定結果（PC）: 値段や契約について 私が選んだ部屋は、マンション単位でJCOMの「In My Room」という契約をしているようで、以下のような特典が無料でついています。\nテレビ：無料～割引料金でご利用可能 ネット：320M コース無料/ 1G コースまでご利用可能 Wi-Fi無料 よくあるマンションレベルでJCOMと契約している無料ネットです。上記の通り320MBコース（下り320、上り10）であれば無料で利用することができます。\n私は無料枠の上り10MB制限というのがネックで、光回線を別途引き込む予定でした。ですが、1GBコースにグレードアップが可能でしたのでこちらを利用しています。しかも、料金は上乗せ分だけで利用可能なので、月1,000円ちょっとで今のコースを利用できています。さらに最初の2ヶ月は無料でした。\nJCOMは普通に同じ条件で契約しようとすると光回線よりも高くなると書いている記事もありましたが、「In My Room」であればかなりお得に利用することができます。\n当初は別途光回線を部屋に引っ張朗と思っていましたが、月1000円ちょっとでこのクオリティならこのままで良いと考えています。\n部屋探し時のポイント ネットでこのあたりのことを検索すると、広告収入で稼ぎたいだけの質の悪い記事（一般論ばかりで経験談がない）が大量に出てくるのでなかなか大変でした。私の投稿の質が高いというわけではありませんが、なにか質問等あれば右下のチャットから質問していただければと思います。分かる範囲で回答いたします！\n注意点 在宅ワークやオンラインゲームをする人が増えたことで、住まいのネット環境を重視する人は増えていると思います。しかし、SUUMOなどに載っている「ネット無料」物件を調べもせずに選択すると、痛い目に合う可能性があります。実際、無料のJCOMでも120MBコースやそれよりも容量が低いものがありますので注意が必要です。\nネット無料物件は、マンション全体でオーナーが契約しているパターンがほとんどなので、実態によっては全然スピードが出ないということがよくあるそうです。また、マンションで契約している回線以外は利用不可という物件もあります。\n私が最終的に選んだ部屋は以下の条件でした。\nJCOMのIn My Roomに契約しており無料ネットが使用可能（課金すればグレードアップ可能） 光回線を別途引くことができる 無料ネットのJCOMで不満があれば光回線を引けば良いので好都合な物件です。\n部屋を探しているときに候補に上がっていた他の部屋は、「UCOM光 レジデンス マンション全戸一括マルチタイプ 上下最大1Gbps LAN配線方式」を無料で使えるところでした。こちらは 「UCOM光以外は使用不可＝光回線の工事などは不可」 という物件で、もし実際に使ってみてネットに不満があった場合は引っ越すしかなくなくなってしまいます。UCOM光を引いている物件はこのパターンが多いそうなので気をつけておくと良いと思います。\nちなみにUCOM光に付いてTwitterなどで調べてみると、問題なく使えている方もいらっしゃったので、UCOM光でも契約タイプによっては問題なく使えるのだと思います。\n調べ方 では、自分の気になっている部屋（物件）が、どういうネット環境になっているか、どのようにして調査するかというと、大きく分けて2つ方法があります。\n不動産屋経由でオーナー（管理会社）に確認してもらう 各種サービス提供サイトのエリア検索から確認する 不動産屋経由でオーナー（管理会社）に確認 まず1つ目は、「不動産屋に部屋のネット状況についてオーナー（管理会社）に確認してもらう」です。これが最も確実な方法になります。気になっている部屋に関して、内見に行く前でもよいので、以下の2点を確認してもらうようお願いすると良いと思います。\n無料ネットであれば、どのプロバイダ（JCOMとかUCOM光等）のどんな契約（名前や上り下り）なのか 別回線（光回線、NURO等）を自分で引き込むことができるのかどうか 先程も書きましたが、「ネット無料」物件が増えてきていることもあり、不動産屋としては「ネットが無料で使える」という情報だけを伝えるので、無料でもどういう契約のもとに無料なのかを確認したほうが良いです。そうすれば、上り下りの速度を知ることができたり、ネットで自分で調べることができるようになります。\n続いて、別回線を部屋に引くことができるかを確認してください。こちらも上述の内容と重なりますが、無料ネットが遅かった場合に自分で新たに別回線を引き込むことができるかは大事な要素になります。無料ネットが使い物にならず、新たな契約（工事）もしてはいけないとなると、我慢するか引っ越しということになります。\n後述のエリア検索を使って自分で確認した場合も、最終的には不動産屋経由で確認を取ったほうが確実だとは思います。\n各種サービス提供サイトのエリア検索から確認 もう一つの調べ方として各種サービス提供会社が用意しているエリア検索を利用して、対象の部屋がそのサービスに対応しているか調査するという方法があります。\n例えば、私が契約しているJCOMであれば、https://www.jcom.co.jp/mdu_search/index.php←こちらのリンクより検索可能です。ネット無料物件であれば、JCOMかUCOM光あたりを調べるのが良いかと思います。※UCOM光 建物検索：https://ucom-r.ne.jp/search.html\n光回線の契約についてはプロバイダなんかの知識も必要になるのですが、それは別途調べていただくということにして、基本的にはNTTが提供している「サービス提供エリア確認・お申し込み | NTT西日本 - フレッツ光」または「住所選択｜提供エリアの確認｜NTT東日本フレッツ公式」から検索し、対応エリアになっていれば基本的に光回線を引き込むことができると考えて問題ないです。\nしかしこの方法では「対象の物件がそもそもどのサービスなのか分からない」という問題があります。光回線に対応しているかどうかはNTTのエリア検索でおおよそ判断できますが、無料ネットの場合はなかなか調べられません。そうなると、やはり不動産屋経由で聞いてもらう、ということになると思います。\n実際、私もこちらの方法でおおよそ調べておいて、最終的には不動産屋経由で確認してもらいました。\nまとめ 今回はネット環境について調べたことや、実際に利用してみた感想をまとめました。\nネットではボロクソに言われがちなJCOMですが、私は問題なく使えているということが伝われば幸いです。この記事を書いたあとに「やっぱりクソでした」とならないことを願うばかりですが（笑）\n","description":"ひとり暮らしを始めてみて、初のJ:COM回線だったのでその感想","id":12,"section":"posts","tags":["感想","workstation"],"title":"J:COM NET 1GBコースを使ってみて","uri":"https://rakuichi4817.github.io/posts/impression-jcom-net/"},{"content":"特にきっかけとかはないのですが、なんとなく利用するブラウザをchromeからedgeに変えてみたので感想を書いてみようと思います。ネットに転がっているような「パフォーマンスを比べてみた」とかはしていないので、あくまで感想です。\n移行した理由 chromeからedgeに移行した理由を強いてあげるなら以下の点かなと思います。\nedge自体がchromeとほぼ変わらないから（Chromium採用のため） edgeがWindows環境に最適化されているから 仕事の関係でどうしてもマイクロソフト系の製品を利用する機会が増えたから edgeのベースがchromeと同じになっていることは割と有名だと思います。その上、Microsoftが開発しているということもあり、Windows環境においてはedgeのほうが良いパフォーマンスを発揮することがいろいろな記事や公式からの案内で紹介されています。\n↓chromeとの比較記事\n上記のサイトでは、メモリ使用量やその他のパフォーマンス面においてedgeが優勢であることを紹介しています。他にも様々なところでパフォーマンスはedgeが良いぜ！と言っています。\nまた、仕事の関係でお客様環境で作業することもあり、その際には別のマイクロソフトアカウントでの作業が必要になることも多くなっていました。今まではchrome上でマイクロソフトアカウントにログインし、切替時にはログアウトして再度ログイン。といった手順を踏んでいました。\nしかし、これではブックマークやその他の設定はそのままになるので、不都合が出る事がありました。特に最近はリモートワークの関係で画面共有をする際に、社内用のブックマークが写ったり、検索履歴が写ったり\u0026hellip;\nそれであれば、お客様環境用のマイクロソフトアカウントでedgeのプロファイルを作成すればよくね？と考えたのも理由の１つになります。\n移行してみて 実際に移行してみて 「edgeでええやん」 というのが率直な感想になります。「メモリ効率がいいわ！」、「処理が軽い！」のような具体的理由があるわけではないのですが、これと言って不都合な点がないので「edgeでええやん」となっています。\n一応、良かったところと気になるところをまとめておきます。\n良かったところ chromeをいちいち入れる必要がなくなる マイクロソフトアカウントとプロファイルを関連付けることでお客様環境への切り替えがしやすい それぞれの環境毎にブックマークなどを反映できるのでありがたい chromeの拡張機能も入れることができるので操作感が変わらない IEモードがあるので、どうしてもIE限定の環境を触らないといけないときにそのまま利用可能 chromeより軽い気がする 個人的には使用感がchromeとほぼ変わらない上に、パフォーマンスが高いのであればedgeでよくね？という感覚になっています。\n気になるところ プロファイルを違う環境で共有するにはマイクロソフトアカウントがプロファイルの数だけ必要 「新しいタブを開く」ときの設定が基本設定ではいじれない chormeでは「プライベート用」と「テック用」の2つのプロファイルを作成していました。また、それぞれのプロファイルとgoogleアカウントを紐付けていたので、スマホでもその他の環境でも、ログインすればブラウザの設定を共有することができました。edgeでももちろんプロファイルの共有は可能なのですが、こちらはマイクロソフトアカウントとの紐付けになります。\ngoogleアカウントとは違い、マイクロソフトのアカウントはオフィスソフトとも関連づいていたり、そもそもWindowsにログインする際にも使ったりするので、プライベートでアカウントを複数作ることは基本的にないと思います。\n私の場合は「テック用」はプロファイルの紐付けは行っていません。そのため、プライベートPCの「テック用」プロファイル上で設定を変えたり、ブックマークを追加しても他のデバイスへ反映する方法がないです。\n※一度chromeを挟むことで他PCにも反映可能ではある「edge→chrome→（別PC）chrome→（別PC）edge」\nまた、新しいタブを開く際にedge専用（bing）のタブが開かれるようになります。新しいタブを開いた際にデフォルトでyahooやgoogleを開くということができないので注意が必要です（拡張機能を入れてgoogleにすることはできる）。\nただ、この点に関して私はそこまで気にしていません。edge専用のタブが開かれて困るポイントがあるとすれば、ページ上の検索エンジンが「bing」になることです。しかし、私は新しいタブを開いて検索する際には、アドレスバーに入力するため、こちらの設定をgoogle検索に変えておけば全く問題ありませんでした。\nまとめ 雑に移行した感想を書いてみましたが、edgeに移行してみて数週間特に困ることなく使えています。スマホ上のブラウザとの連携という点では、少しむずかしいなーということもありますが、それを踏まえてもedgeでええかという感じです。\n昔は「edge（IE）使ってんの？」という雰囲気がありましたが、逆に今は「なんであえてchromeなの？」という雰囲気になっていくのでしょうか\u0026hellip;\n移行時の参考 ","description":"なんとなくですがedgeに移行してみたのでその感想","id":13,"section":"posts","tags":["環境構築","Web","アプリ"],"title":"脱chromeしてedgeに移行してみた","uri":"https://rakuichi4817.github.io/posts/chrome-to-edge/"},{"content":"タイトルの通り、GitHub Actionsでpytestを実行し、テストが失敗（Failed）したときの挙動について確認してみました。\n前回の記事「GitHub Actions・pipenv・pytestで自動テストの練習」で、一連の流れの確認をしてみたのですが、テストが失敗のときはどうやって判断できるのだろうか？と思い、実際に試し、そのまとめになります（当たり前のことなのかもしれませんが、勉強なのであしからず）。\n失敗するテストを作成 基本的な構成は「GitHub Actions・pipenv・pytestで自動テストの練習」と全く同じにしています。失敗するテストの挙動を確認するために「pytest-failed」ブランチを作成して、そちらでテストの内容だけ、必ず失敗するように書き換えて試してみました。全体感などを確認したい方は上記記事を見てみてください。\n今回利用した実際のリポジトリ：https://github.com/rakuichi4817/study-actions/tree/pytest-failed\n作成した必ず失敗するテストファイルは以下になります。assert 2 == 3となっているため、必ずテストは失敗になります。この状態で変更をコミット・プッシュすることで、GitHub Actions上で失敗するテストが実行可能になります。\n1 2 3 def test_failed(): print(\u0026#34;---failed test---\u0026#34;) assert 2 == 3 GitHub Actionsの確認 プッシュするとエラーに関するメールが届きます。GitHub Actionsでは、処理に問題があるとメールが届く機能があります。下図のように問題があったworkflowへのリンクが貼られています。\nメール内容: Pytestでエラーが出ていることを確認できる GitHub Actions上で結果を確認してみます（あえてメールのリンクを踏んでいません）。\nGitHubのリポジトリ上のActionsタブを見てみると、エラーを吐いていることが確認できます。ここでもworkflowがエラーとなっていることが判断できます。\nリポジトリのActionsタブ: 失敗しているテストでエラーが確認できる ここで、今回のプッシュに該当する一番上のworkflowの詳細の確認をします。\nStatusがFailureとなっていることがわかります。さらに「Annotations」が追加され、エラーに関する内容が書かれています。ただ、ここでは、「処理の中でエラーが発生したよ」くらいしかわかりません。軽く調べてみたところ、ここにエラー箇所を表示する方法もあるみたいです。\nエラーworkflowの詳細: StatusがFailure 今回はそのまま「build」ジョブの中身を見て、エラーが出ているステップを確認します。\n「Test with pytest」ステップでエラーが出ていることがわかり、そのまま詳細情報が表示されます（開いたときに自動で詳細も表示されました）。前節で作成した、失敗するテスト内容assert 2 == 3のところでFAILEDが出ていることがわかります。\nエラーjobの詳細: Pytestでエラーが出ていることを確認できる まとめ 今回は、GitHub Actionsでpytestが失敗したときにどういった挙動になるのかを確認しました。\npytestに失敗するとworkflowも失敗となり、お知らせメールが届くことを学べました。しかし、具体的なエラー内容はジョブの詳細を開くしかなく、Annotationsでは判断できません。このあたりは、カスタマイズすることでエラー箇所をAnnotationしたりもできるのかなと思っています。\n次回以降、このあたりの勉強もできれば\u0026hellip;。\n","description":"シンプルにGitHub Actionsでpytestを動かし、テストが失敗した場合の挙動を見てみました。","id":14,"section":"posts","tags":["Python","pytest","GitHub","GitHub Actions","テスト","CI/CD"],"title":"GitHub Actions・pytestで失敗した(Failed)時の挙動確認","uri":"https://rakuichi4817.github.io/posts/github-actions-pytest-failed/"},{"content":"タイトルの通り、GitHub Actionsを用いてPythonのテスト自動化に取り組んでみました。テストについては、もちろんpytestを利用するのですが、今回はpythonパッケージの依存関係をpipenvで管理している場合を想定します。練習なので、最低限動作するレベルの内容であり、ベストプラクティスというわけではないのでご注意ください。\nGitHub Actionsのワークフロー定義のみ見たいという方は「#3-github-actionsのワークフローファイルの作成」をクリックしてください。\nGitHub Actionsについて 詳細は触れませんが、簡単な紹介と参考ページのリンクを貼っておきます。\n概要 GitHub Actionsは、GitHubのリポジトリに対して、様々な条件のトリガーを元に定義しておいた処理を実行する機能になります。トリガーにはプッシュやプルリクエストといった処理や定時実行などがあり、GitHubが提供するサーバー上の仮想マシンで実行できます。\n無料枠における制限であったり、できることの説明は色々あるのですが、ここでは割愛させていただきます。\n今回は、「プッシュしたときにPythonコードのテスト(pytest)を実行する」 を目標にこちらを活用します。\n公式ドキュメントと参考ページ 実際の構成やソース（サンプルプロジェクト） 以下のステップで進めていきます。\npipenv環境の構築 テスト対象プログラムとテストプログラムの作成 GitHub Actionsのワークフローファイルの作成 GitHubへのプッシュと確認 内容としては、単純な足し算をする関数のテストをプッシュ時に実行する、というものになります。\n1. pipenv環境の構築 最近はPythonプログラムを作成する際、pipenvで環境を構築することが増えたので、今回もpipenvで環境を作っていきます。とはいっても、簡単な関数しか作成しないので、pytestのみインストールします。GitHub Actionsでは、このpipenvの仮想環境上でpytestを実行します。\n1 2 3 4 # 仮想環境の作成（Pythonバージョン3.9系） $ py -m pipenv --python 3.9 # pytestの導入 $ pipenv install pytest 2. テスト対象プログラムとテストプログラムの作成 2.1 全体 実際に練習で作成したリポジトリはこちらです↓\nhttps://github.com/rakuichi4817/study-actions/tree/pytest-quickstart\nファイル構成は以下のようになっています（一部省略しています）。よく見るファイル構成を元にして、srcディレクトリとtestsディレクトリを作成しています。srcディレクトリにメインとなるソース、testsディレクトリにテスト用ソースを置いています。\n1 2 3 4 5 6 7 8 9 10 .github/workflows - GitHub Actions用ディレクトリ └── pytest-all.yml - ワークフロー定義ファイル src ├── __init__.py └── sample.py - テスト対象コード tests ├── __init__.py └── test_sample.py - pytestコード Pipfile Pipfile.lock 2.2 テスト対象プログラムとテストプログラム テスト対象となる足し算関数のプログラムと、その関数のテスト用プログラムを作成します。テストは成功するものを書いています（テスト名はtest_addの方がいい気がします）。\n1 2 def add(a: int, b: int) -\u0026gt; int: return a + b 1 2 3 4 5 from src.sample import add def test_passing(): print(\u0026#34;---pass test---\u0026#34;) assert add(1, 2) == 3 一旦ローカル上で、上記のテストが正しく動作するか確認しておきます。\n1 2 3 4 5 6 7 8 9 10 11 $ study-actions\u0026gt; pipenv run pytest -v -s ============================== test session starts =============================== platform win32 -- Python 3.9.6, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- ~\\study-actions\\.venv\\scripts\\python.exe cachedir: .pytest_cache rootdir: ~\\study-actions collected 1 item tests/test_sample.py::test_passing ---pass test--- PASSED =============================== 1 passed in 0.03s ================================ 問題なく実行されているのが確認できるかと思います。pytestについては勉強中なので、また別記事で学習記録でも書くつもりです。\n3. GitHub Actionsのワークフローファイルの作成 GitHub ActionsでPython環境を作成するために、GitHub Marketplaceで提供されている「Setup Python」を利用します。ワークフローの説明については省きますが、動作としては「リポジトリにプッシュした際にpytestを走らせる」というものになります。pipenvを利用しているのですが、こちらの対応は、上記リンクの公式ドキュメントに書いていましたので、ほぼそのまま利用しました。\n本来であればビルドジョブとテストジョブを分けるべきなのでしょうが、今回はまとめています。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 name: Pytest on: [push] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Install pipenv run: pipx install pipenv - name: Set up pipenv uses: actions/setup-python@v2 with: python-version: \u0026#34;3.9\u0026#34; cache: \u0026#34;pipenv\u0026#34; - run: pipenv install - name: Test with pytest run: pipenv run pytest -v -s 4. プッシュとActionsの確認 作成したコードをプッシュし、GitHubのリポジトリページにあるActionsタブを確認します。下図でみていくと、左側のWorkflowsの「Pytest」が今回作成したワークフローになり、右下には実際に走ったワークフローが確認できます。実は一度ワークフローファイルの定義でエラーがでたのですが、その時のログも残っています。\nリポジトリのActionsタブ: プッシュされたタイミングの最新コミット名が表示される 成功したときのワークフローログを見ます。前節でも書きましたが、今回は1つのジョブでテストまで走らせているので、表示されるジョブは「build」1つです。\n成功ワークフロー: Jobs「build」が表示される 「build」をクリックすると、詳細な処理ステップと出力を確認することができます。また、\u0026gt;をクリックすると各ステップの出力が表示されます。\nログを見ると、テストが成功していることを確認できます。さらに、こちらで定義したステップに加え、クリーンアップを行うステップが自動で追加されていました。\nジョブの詳細ログ: pytest部分を確認 まとめと今後 今回はGitHub Actionsを使った自動テストの練習として、pytestとpipenvを組み合わせたPythonのテストに挑戦しました。GitHub Actionsもpytestも勉強中なので、良くない書き方もしているかと思います。とはいえ、とりあえず動くものがあったほうが理解が進むので\u0026hellip;。説明の中でも触れましたが、テストのジョブは分けるべきなのかな？と思ったりします。\nテストに失敗したときに、ジョブとしては失敗になるのか試していないので、そちらも確認していきたいと思っています。これからも勉強を続けて、備忘録代わりに記事を書いていきます。\n","description":"pipenv環境で作成したPythonプログラムの自動テストのために、GitHub Actionsとpytestのサンプルを作成しました。","id":15,"section":"posts","tags":["Python","pytest","GitHub","GitHub Actions","テスト","CI/CD"],"title":"GitHub Actions・pipenv・pytestで自動テストの練習","uri":"https://rakuichi4817.github.io/posts/github-actions-pytest/"},{"content":"2021年も終わりということで、今年の簡単な振り返りと、2022年にしたいことや目標でも書こうと思います。\n2021年振り返り 今年の上半期はメンタル的にはあまりよろしくない時期が続きました。仕事や技術学習に対するモチベーションが下がったりしていましたが、下半期は持ち直して、結果的には良い1年だったなと思えます。サポートしてくださった方々に感謝です。\n映画にどっぷり、ミュージカルにもハマる あまりどこかに出かけるということはできませんでしたが、映画をたくさん見ることができた1年でした。また、（ほぼ）初めてのミュージカルに行くという経験もできました。\n映画に関しては、6月くらいから見た映画のログを取るようになり、見返すと51の映画を見ていました。来年はもっと見たいなと思います。ちなみに、特に良かったなと思った映画は「BEGIN AGAIN（邦題：はじまりのうた BEGIN AGAIN）」と「Chef（邦題：シェフ 三ツ星フードトラック始めました）」です。\nミュージカルに関しては、年始に博多座でローマの休日を見に行くことができました。学校のイベントを除けば初めて行く舞台でした。ミュージカル映画はよく見ているのですが、生で見る演技の迫力や魅力、舞台セットの凄さに終始圧倒されました。幸せなことに、最前列で見ることができたのも貴重な経験でした。\nローマの休日: ほぼ初めてのミュージカル すっかり生ミュージカルにハマった私は、「レ・ミゼラブル」と「エニシング・ゴーズ」のチケットをとったのですが、コロナで中止になってしまったのが残念でした。すでに来年1月の「マイ・フェア・レディ」のチケットを取っているので楽しみにしています。舞台版の北斗の拳も少し気になってます\u0026hellip;\nヴィッセル3位！アツアレ！ 2021年はそれなりにヴィッセルの試合にも行けました。アウェイの試合にはあまりいけませんでしたが\u0026hellip;。街中でヴィッセルの選手と遭遇したり、ジェラピケコラボウェアを買ったり、かなりヴィッセル漬けで楽しい1年でした。\n推しの選手である古橋選手のシーズン中の移籍がありながらも、大迫選手、武藤選手、ボージャン選手という豪華補強もあり、シーズン3位フィニッシュ。来年のACLが楽しみです！アツアレ！\nヴィッセル3位: フィナーレイベント シーズン終了後にはフェルマーレンの退団という悲しいこともありましたが、来年もヴィッセルを楽しみに頑張るぞ！（ちなみにシーズンシート買いました）\nその他もろもろ\u0026hellip; 今年の写真を見返すと、ヴィッセルと映画を除いたとき、あまり目立った写真はなかったです\u0026hellip;。しかし、仕事でお世話になった方とご飯に行ったり、仲の良い友人とサウナに行ったりと、身近な人とのつながりを大事にできたと思います。\nそんな中でも、年末には行きたかったUSJのスーパーニンテンドーワールドに行くことができました。朝9時から入場して整理券をとったところ、まさかの17:20入場。コロナが落ち着いていた12月の初めに行ったからだと思いますが、結構人がいてびっくりしました。\n土管に入るときのワクワク感や、音楽を聞いたときの懐かしい感じがたまらなかったです。ヨッシーの背中にのるアトラクションが動いていなかったのが残念でしたが、また訪れてみたいです。来年はディズニーにも行きたい！\nスーパーニンテンドーワールド: USJの新エリア！ 仕事面でいうと、取らないといけなかった応用情報技術者の資格を取得できました。社内でもいろいろなコミュニティを立ち上げたり参加したり、様々な部署の人と関わることができました。これからも、もっともっと技術力を向上させて、頼られる存在になりたいと思っています。\n2022年したいこと・目標 とりあえずしたいこと2つです。\n旅行（ヴィッセルのアウェイ観戦） 映画館にもっと行く 特にしたいことは旅行（ヴィッセルのアウェイ観戦）です。なかなかコロナの影響で見に行くことができなかったので、2022年こそはしてみたいなと。温泉が好きなので各地の温泉をめぐりつつ、ヴィッセルのアウェイの試合も見ていく事ができれば最高です。コンサドーレの試合を見た帰りにイクラ丼でも食べて帰りたいですね。\n2つ目のしたいことですが、映画館に月1回以上行きたいなと思っています。振り返りにも書きましたが、2021年の下半期は結構な数の映画を見ました。ただ、サブスク系で見ることが多かったので、映画館に行く回数を増やしたいです。アクションやミュージカル系の映画をドルビーシネマで見てみたいですね。また、興味のあるミュージカルも積極的に見に行こうと思っています。\n今思いついている目標はAWS系の資格をとることくらいです。自分でAWSのアーキテクチャを考えられるような能力を身に着けたいと思っています。他になにか目標と言えることはあまりありませんが、ひとり暮らしを始める予定なので、楽しみながら色々経験していきたいです。\n最後になりますが,,,皆さん良いお年を！そして2022年が素敵な1年になりますように！\n","description":"2021年の振り返りと2022年にしたいことを簡単に書いてみます。","id":16,"section":"posts","tags":["写真","感想"],"title":"2021年の振り返りと2022年にしたいこと","uri":"https://rakuichi4817.github.io/posts/2021-summary/"},{"content":"久々の投稿です（n回目）。またしてもブログの投稿をサボっていました。個人的に日記も書くようにしているので、それに加えてブログの記事を書くというのはなかなか腰が重かったです\u0026hellip;。それでも、年末に向けて多少投稿していこうと思い、まずは手軽な話題から書いていきます。\n今回は、最近購入し愛用しているバックパック 、WEXLEY「SHELDRAKE BACKPACK」 を紹介しようと思います。\n今まで、Arc\u0026rsquo;teryx「マンティス 26 バックパック」 を愛用してきました。マンティス26でも十分満足しているのですが、少しヘタってきたのと、もう少し小さめのがほしいという気持ちが出てきて、SHELDRAKE BACKPACKを購入しました。今年に出た新作ということで、マンティス26に比べると、ネット上に参考記事が上がっていないので、これから買う人の参考になればと思います。\n※記事の内容で気なることがある方はチャット欄から質問してみてください！\n大きさなどの全体感 公式サイトの方でかなり細かく仕様が書かれており、様々な角度から撮られた写真ものっています。私も基本的にはこの公式サイトを見て購入を決断しました。ちなみに、お値段は22,000円ですが、instagramで検索するとクーポンコードを紹介してくださっている方がいるので、そちらを利用するとお安くなりました！\nWEXLEY 商品ページURL：https://wexley.jp/products/sheldrake 厳密に私が買ったのは、「SHELDRAKE BACKPACK」で、素材\u0026amp;カラーが「1050D FULL CORDURA BALLISTIC BLACK」のものになります。 素材\u0026amp;カラーが違うと、重量、撥水性や生地の耐久力などが変わってきます。もちろん値段も違います。この点には注意が必要です。 細かいパーツの説明や、利用されている素材の説明はぜひ公式サイトを御覧ください！\nリュックとして気になる主な仕様を上記公式サイトから抜粋します。\nサイズ\nW27 x H46 x D16cm（内容量17L）\n重量\n・CORDURA COATED: 0.8kg\n・FULL CORDURA: 0.8kg\n・FULL CORDURA BALLISTIC: 0.9kg\n・X-PAC X50 TACTICAL KEVLAR: 0.8kg\nちなみにマンティス26のスペックは以下になります。\nサイズ\nW29 × H51 × D25cm （内容量26L）\n重量\n0.93kg\nSHELDRAKE BACKPACKとマンティス26の比較①\nSHELDRAKE BACKPACKとマンティス26の比較②\nマンティス26よりひと回り小さくて、厚みが薄いぶん容量が少なくなっているという感じです。マンティス26は荷物を詰め込むとかなり膨らんで、バッグ上側が分厚くなっていきます。それに比べSHELDRAKE BACKPACKはあまり膨らみません。上の画像でも見ていただくとわかると思いますが、厚みは明確に違います（SHELDRAKE BACKPACKの中に何も入れていないので、若干膨らみきっていないところはあります）。そのため、内容量に17Lと26Lという違いがあります。\n私はマンティス26より小さいものが欲しかったので、コンパクトになっているのは満足ポイントの1つです。マンティス26はポケットに色々入れていくと、全体的に荷物が少なくても膨らんでしまっていたのですが、SHELDRAKEは（内包量が少ないので）シュッとしたデザインを保つことができます。\nメイン収納部分 主な収納部分は2つに分かれています。体から遠い方を外側、体に近い方を内側として紹介します。\n公式サイトにも書かれていますが、外側にガジェットや小物類、内側にラップトップPCや本などを入れるといいと思います。\n外側（体から離れている方）のメイン収納 外側の収納部分の特徴はポケットの多さです。下の写真では試しにiPhone8を入れてみていますので、サイズ感を見ていただければと思います（ポケットの底にiPhoneはついています）。このサイズのポケットが2つと、そこにさらに黒いメッシュのような生地がついており、小物が入れられる様になっています（実は下の写真でも目薬を入れてます）。さらにペンホルダーが2つと、ファスナーが付いているポケット、そしてその中にキーホルダーが付いています。ファスナーがついているポケットは比較的深めとなっており、手前にあるポケットと底の位置は一緒になっています。\n外側のメイン収納にあるポケット\n注意しておく点もあります。それは収納口の開き具合はあまり広くないことです。これは、リュック自体がコンパクトな（厚みが薄い）なのと、メイン収納が2つに分かれているからだと思います。もう一つのメイン収納部分については後ほど触れますが、収納部分が2つに分かれているので、どちらかに厚みのある荷物を入れると、もう片方は圧迫されてしまいます。それでも、十分な収納力があるのであまり気になりません。\nあえて「注意しておく点」として触れましたが、どちらかというと「認識している方が良い点」ですかね。私はマンティス26との差別化ということで、膨らみすぎないものが欲しかったのでオッケーかなと思います。\n外側のメイン収納の開き具合\n内側（体側）のメイン収納 内側のメイン収納の特徴はラップトップPCを入れることができるスリーブポケットがついていることです。他にもファスナーがついたメッシュのポケットが付いています。スリーブポケットはクッションのような素材で囲まれているので、衝撃からPCを守ってくれます。ちなみに公式サイトには、以下のようにスリーブポケットの仕様が載っています。\n・Mac Book 15インチ相当のラップトップが収納可能\n・ラップトップ用スリーブポケット (内寸W27 x H41 x D2cm)\nThinkPad X390を入れてみましたが、もちろんすっぽり入りました。同時にiPadを入れたりすることもできます。A4サイズのファイルなども入れることができるので、PCを持ち運ばない人でも便利に使えると思います。\n外側のメイン収納のところでも触れましたが、こちらは開き具合がより狭くなっています。また、内側外側ともに、開閉部分のファスナーは硬い印象です。おそらく防水性などを保つためにしっかりしていると思うのですが、慣れるまでは少し違和感があります。\n内側のメイン収納にあるPC用スリーブポケット\n内側のメイン収納の開き具合\nその他収納 その他の収納として、トップ部分に1つ、背中側に2つポケットがついています。\nトップ部分のポケットは、かなり圧迫感があるのであまり物入れられませんが、iPhone8くらいなら問題なく入ります。圧迫感があるので、厚みのあるものを入れるのには向いていません。\n背中側のポケットは2箇所存在しており、こちらも両方iPhoneは問題なく入る大きさとなっています。更に片方のポケットにはカードのスキミング防止機能がついており、こちらに財布や定期入れを入れるようにしています。トップ部分のポケット同様、あまり厚みのあるものを入れるのには向いてなさそうではあります。\nトップ部分のポケット\n背中側の2つのポケット\n背負った感じ もともとマンティス26を使っていたこともあり、背負ったときの感覚はかなり大事にしていました。マンティス26は背中にフィットするような感じになっていて、非常に背負いやすかったからです。背負う部分が柔らかいリュックはちょっと嫌だなと思っていたのですが、「SHELDRAKE BACKPACK」は、背中部分がほどよく固くなっており充分背負いやすかったです。マンティス26のように背中にフィットするような感覚はあまりありませんが、気になるほどでもありません。満足して使えると思います。\nまとめ 色々書いてきましたが、ざっとまとめると、\nポジティブな点 かっこいい デザインが落ち着いているので普段使いにできる コンパクトにまとまる 収納箇所が多い 背負いやすい ネガティブな点 ファスナーが若干きつい（作りがしっかりしているとも言える） メイン収納部分の開きが控えめ（コンパクトなので仕方がない） トップ部分のポケットに何入れようか\u0026hellip; こんな感じかなと思います。ネガティブな点としてあげている部分も強いて言うならというぐらいなので、総合的に非常に満足しています。\n私は荷物に小物を入れがちなので、収納箇所が多いのは推しポイントです。また、デザインがシンプルでコンパクトなので、お出かけ時にも使いやすいのではと思います。また、女性でも使いやすいサイズ感だと思います。\nなにか気になる点や、聞いてみたいことがあることはぜひ右下のチャット欄から質問してみてください。決して安い買い物ではないので参考になれば幸いです。\n","description":"PC持ち運び時にも、普段使いにもピッタリのリュック、SHELDRAKE BACKPACKを購入しました","id":17,"section":"posts","tags":["ガジェット","日用品"],"title":"WEXLEY SHELDRAKE BACKPACK 紹介","uri":"https://rakuichi4817.github.io/posts/buy-wexley-sheldrake/"},{"content":"大学4年からPythonを触りだしましたが、その時から一貫してAnacondaでPythonの環境を作成していました。しかし、脱AnacondaしてPipenvに乗り換えたので、簡単にまとめようかと思います。\nAnacondaを利用していた理由とやめた理由 特にこだわりがあってAnacondaを利用していたわけではなく、右も左も分からないときに最初に使ったのがAnacondaで、結果的にずっと利用していました。研究室に配属された新人向けに、Pythonの環境構築としてAnacondaの説明が載っていたのです。\n配属されるまで、授業以外でプログラミングなどに触れず、環境構築すらよくわかってなかった自分にとっては、とりあえずAnacondaで良かったかなとは思います。研究で使う最低限のライブラリも最初から入ってますし、個人で研究などに使う分には今でもAnacondaでも良いのかなと思います。おそらく研究室の方針としてもそういった意図があり、入ってきた生徒にAnacondaによる環境構築を説明していたのだと思います。\nしかし、最近は自分の作ったプログラムを他の人の環境で動かしてもらうことが多くなりました。そのときに、「じゃあAnacondaを入れてcondaで仮想環境を作って」というわけにもいかず、condaとpipを混ぜてしまう危険性※（最近は問題ないとか）もあったりと、多くの問題が発生しました。\n※ わりと有名だと思っている記事：condaとpip：混ぜるな危険\n何より、そもそも会社で使うには有償なんですよね。（まとめてくださっている記事：Anaconda パッケージリポジトリが「大規模な」商用利用では有償になっていた）\nさらに、自分自身で使うときも複数の環境でコードを実行することが増え、そのたびにAnacondaで環境を作るのがめんどくさくなっていました。そこで、思い切って環境の作り方を変えようということで、こちらの記事「Anacondaが有償化されて困っている人に贈る、Pythonのパッケージ管理」を参考にして、Pipenvで環境を作ることにしました。\nPipenvを選んだ理由は仮想環境を作って開発環境を揃える事ができそうだから、というのが一番の理由です。私も自分の状況を見ながら、上の記事を参考にして決めました。Pipenvに変えてしばらくしますが、非常に満足しています。\n脱AnacondaとPipenvの導入 脱Anaconda まず、Anacondaで作った環境を削除します。基本的にはこちらの公式ドキュメントを参考にしていただければと思います。\nステップは以下の2つです。\nanaconda-cleanで関連ファイルをまとめて削除 コントロールパネルからPythonの削除 Anacondaをインストールすると、様々な環境情報が色んな所に保存されます。それらをまとめて削除してくれるanaconda-cleanを導入します。下記コマンドで、導入、実行を行うとホームディレクトリに.anaconda_backupというディレクトリが作成されます。必要がなければこちらのファイルも消して良いと思います。\n1 2 conda install anaconda-clean anaconda-clean --yes 続いて、コントロールパネルから「Python 3.x.x（Anaconda 3.x.x）」のアンインストールを実行すれば、脱Anacondaの完了です。\nPythonとPipenvの導入 まずは純正のPythonをインストールします。私はPython.jpでまとめてくれている以下のダウンロードリンクから最新版をダウンロードしました。ダウンロードできたらインストーラを起動します。\n※ダウンロードリンク：https://pythonlinks.python.jp/ja/index.html\nインストーラを起動したら「Add Python 3.〇 to PATH」にチェックを入れるようにします。インストールが完了したら、pipでpipenvをインストールします。\n1 pip install pipenv 続いて、環境変数を設定していきます。デフォルトでは、Pipenvで環境を作る際に、その環境ファイルがホームディレクトリに作成されてしまいます。こちらの設定をすることによって、実行したカレントディレクトリ（プロジェクト）配下に作成することができます。\n環境変数名にPIPENV_VENV_IN_PROJECT、変数値にtrueを設定すればOKです。\n環境変数の設定\nこれで最低限の設定は完了になります。\n試しに仮想環境を作ってみる 試しに仮想環境を作ってみます。先程のPythonの導入でPython3.9を入れていたとします。この状態で、Python3.8の仮想環境を作ってみます。手順としては以下の通りになります。\nPython3.8をインストール（「Add Python 3.〇 to PATH」にチェックを入れない） プロジェクトディレクトリの作成 pipenvで仮想環境を作成 ここで、PipenvでPythonのバージョンを指定して環境構築する際の注意事項について、以下にまとめておきます（Python3.8で仮想環境を構築する前提）。\nPython3.9がすでに入っていても、Python3.8も別に入れる必要がある すでに導入されているPythonがバージョン3.8系である場合は入れる必要はない Pythonのバージョンは3.△.〇が存在するが、△が違う場合は別のものとしてインストールされ、〇が違うものに関しては、最新版で上書きされる Python3.9.1とPython3.8.1は別でインストール Python3.9.1とPython3.9.2を入れると3.9.2しか残らない 利用したいバージョンのPythonの導入（今回は3.8） まず、Python3.8のインストールを行います。このとき、基本となるPythonとかぶらないよう、「Add Python 3.〇 to PATH」にチェックを入れないようにしておきます。インストールが完了したら下記コマンドで出力を確認します。下記の例ではバージョン3.9と3.8が導入されており、pyで実行すると、基本的には3.9が走ることを確認できます。\n1 2 3 4 \u0026gt; py --list-paths Installed Pythons found by C:\\WINDOWS\\py.exe Launcher for Windows -3.9-64 C:\\Users\\\u0026lt;username\u0026gt;\\AppData\\Local\\Programs\\Python\\Python39\\python.exe * -3.8-64 C:\\Users\\\u0026lt;username\u0026gt;\\AppData\\Local\\Programs\\Python\\Python38\\python.exe プロジェクトディレクトリの作成と仮想環境作成 今回は「check-pipenv」というディレクトリを作成し、その配下で開発をすすめるという前提で仮想環境を作成します。以下のコマンドで簡単に作成することができます。\n1 2 3 mkdir check-pipenv cd check-pipenv py -m pipenv --python 3.8 エクスプローラで確認すると以下のように「.venv」と「Pipfile」が生成されていることがわかります。「.venv」は指定バージョンのPythonであったり、ライブラリの本体が保存されています。一方「Pipfile」には仮想環境の情報がテキストで保存されています。作成した仮想環境のを他の環境で再現する際は、「.venv」は共有する必要はなく、「Pipfile」さえあれば、pipenvで環境を再現することができます。\n作成されるファイル\nPythonのバージョンが3.8として認識されているかを確認したい場合は、pipenv shellを実行して、仮想環境に入ってからpython --versionを実行するか、pipenv run python --versionを実行することで確認できます。\n1 2 pipenv shell python --version または\n1 pipenv run python --version 仮想環境でPythonを実行したい場合も以上の2種類どちらかの方法で実行することができます。\n仮想環境にライブラリを入れる 作成した仮想環境上にライブラリを入れる場合は、プロジェクトディレクトリ上でpipenv install 〇〇とすればOKです。試しに「numpy」を入れた例を示します。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt;pipenv install numpy Installing numpy... Adding numpy to Pipfile\u0026#39;s [packages]... Installation Succeeded Pipfile.lock not found, creating... Locking [dev-packages] dependencies... Locking [packages] dependencies... Locking...Building requirements... Resolving dependencies... Success! Updated Pipfile.lock (456e4b)! Installing dependencies from Pipfile.lock (456e4b)... ================================ 0/0 - 00:00:00 To activate this project\u0026#39;s virtualenv, run pipenv shell. Alternatively, run a command inside the virtualenv with pipenv run. このコマンドを実行した後、「Pipfile」の中身に「numpy」の情報が書き加えられ、「Pipfile.lock」というファイルも作成されると思います。「.lock」がついているものについては次のセクションで紹介します。\nPipfile（.lock）を用いて仮想環境の再現 今までの手順で、仮想環境の作成とその環境にライブラリを入れる方法がわかったと思います。では、この作成した仮想環境を他の場所、他の人に再現してもらうための手順を紹介します。手順としては非常に簡単で、「Pipfile」または「Pipenv.lock」を共有して、Pipenvのコマンドを走らせるだけです。\nこの時、「.lock」がついているものをもとに環境を構築すると、完全にライブラリのバージョンが揃えられてインストールされます。それぞれのコマンドは以下のとおりです。\n1 2 3 4 # Pipfile.lockを利用する場合 py -m pipenv sync # Pipfileを利用する場合 py -m pipenv install こちらのコマンドを実行すると「.venv」ディレクトリが作成されていることが確認できます。これで、仮想環境の再現が完了となります。\nまとめ 今回はPythonの環境構築をAnacondaからPipenvに変えたことについて、簡単にですがまとめました。このあたりのわかりやすい記事は他にも色々上がっているので、自分の備忘録としてという形です。\n今回の記事では触れていない複数の環境でjupyterを利用するときのカーネル設定の話や、vscodeで開発する際の環境指定の話などは、おいおい投稿しようかなと思います。\nまた、環境を揃えるという意味では、Dockerを使って土台から環境を揃えることも行っています。例えば、言語処理100本ノックの実行環境をDockerで作ってしまう、ということをしていたりします。ただ、若干学習コストが高くなるので、周りの人にすすめる際には難しいなぁと思っていたりもします。\n","description":"Pythonの環境作りをAnacondaからPipenvに変更しました","id":18,"section":"posts","tags":["Python","環境構築"],"title":"脱AnacondaしてPipenvでPython環境作り","uri":"https://rakuichi4817.github.io/posts/start-pipenv/"},{"content":"このブログはHugoを利用して作成しているのですが、利用する基本テーマをZzoに変更し、リニューアルしました。\nHugoテーマのZzoへの変更 もともとはMediumishというテーマを利用していました。基本的には気に入っていたのですが、もう少し色々機能がほしいなと考えていました。そこで新たなテーマを探し、結果的にZzoに変更することにしました。個人的にZzoの気に入っている点が以下になります。\nカラーテーマをサイト上で変えることができる 記事の目次機能（オンオフがパラメータ指定できる） サイドバーに目次をつけることが可能 記事の先頭にも目次をつけることが可能 アーカイブ機能やタグ、カテゴリ、連載機能など、記事をまとめる機能が豊富 他にもギャラリー機能や、ショーケース機能など、豊富なページテンプレートがあります。このあたりは公式ドキュメントを参考にしていただくと良いかと思います。\nブログ全体の調整 投稿していた内容に修正を加えたり、広告の表示を減らすなど、いくつかの変更点を加えました。\n作成したチャットボット「チャントオシエール」に関する記事も一旦消しています。理由としては、今までボットのサーバとして使っていた環境が今後使えなくなりそうだからです。技術的な部分の記事については、修正していつか再アップロードできればと思います。\nチャントオシエール\nまた、投稿頻度を少し上げたいなとも考えています。ブロガーになるつもりはないので、「毎日投稿する！」というわけではないですが、勉強のモチベーションアップも兼ねて投稿しようという狙いです。実は違う名前でnotesもやっています。こちらのブログとnotesをうまく使い分けながら投稿していければと思います。こちらは半分身元がバレている（同じアイコンを色んな所で使っている）ので。\n","description":"HugoのテーマをZzoにしブログをリニューアルしました","id":19,"section":"posts","tags":["Hugo","Web"],"title":"ブログをリニューアルしました","uri":"https://rakuichi4817.github.io/posts/new-theme/"},{"content":"前回に引き続き、2020年に購入したもので買ってよかったなぁと思うものを書いていきます。\n（前回記事：2020年に買ってよかったもの vol.1）\nガジェット 今回は以下の4つをまとめていきます！\nRazer Hammerhead Pro V2 （RZ04-01730100-R3A1） RAVPower 61W USB-C 急速充電器（RP-PC112） RAVPower 90W 2ポートUSB-C 急速充電器（RP-PC128） Anker PowerLine+ III USB-C \u0026amp; USB-C 2.0 ケーブル (1.8m ブラック) 【2021年9月18日追記】\nRAVPowerの製品はAmazonからレビュー問題で締め出されてしまっています。個人的に製品自体は使い勝手が良いですし、気に入っているので複雑な気持ちですが、公式サイトから購入が可能です。 Razer Hammerhead Pro V2 （RZ04-01730100-R3A1）：おすすめ度 ★★☆ PS4のゲーム用に買いました。APEXやらCoDやらをやる際に、ボイスチャットしながらゲームをしたかったので、イヤホンマイクをと思いこちらの商品を選択しました。\n（ヘッドフォンだとメガネのときに痛いので\u0026hellip;）\nゲーム用のイヤホンということでRazerの商品を選択しましたが、ゲームするには十分な音質ですし、ボイスチャットも問題なくできています。また、絡まりにくいコードになっているので、しまうときにある程度雑にしまっても絡まることがないので気に入ってます。\n更に、今年は在宅勤務でのリモート会議で、イヤホンマイクを使う機会が増えたので、有線かつPCにもiPhoneにも対応しているこちらのHammerhead Pro V2は活用シーンが多くて満足しております。\n唯一の不満点があるとすれば、マイクのオンオフをこちらのイヤホンマイクでは調整できない点です。また、Razerの製品は偽物が出回っているそうなので気をつける必要があります。\n【感想まとめ】 良い点 ゲームをするのには十分な音質（FPSで足音の位置もわかりやすい） ボイスチャットが問題なくできる WindowsでもPS4でもiPhoneでも使える コードが絡まりにくい 気になる点 マイクのオンオフを切り替えれない 偽物が出回っている 【実際に購入した販売ページ（Amazon）】 Razer Hammerhead Pro V2 マイク付きゲーミングイヤホン 【日本正規代理店保証品】 RZ04-01730100-R3A1（¥5,480）\n箱とイヤホン\n音量調整とマイク部分\nロゴ\nRAVPower 61W USB-C 急速充電器（RP-PC112）：おすすめ度 ★★★ 社用PCもThinkPadで私用PCもThinkPadですので、Type-Cによる充電することが増えました。その際、付属のACアダプタを持ち運ぶのが重いのと大きいのとで面倒でした。\nこちらの「RAVPower 61W USB-C 急速充電器」を使えば急速充電可能で、iPhone11のようなType-C to Lightningケーブルを使う場合でも対応可能になります。また、重さが105gで大きさが4.9 x 4.9 x 3.2 cmとなっているので、持ち運びが楽です。\nお値段も4,000円前後で、とりあえずType-Cで充電するデバイスを持っている方は買ってみていいと思います！注意点としては充電に必要なケーブルは同梱されていませんので、別途購入する必要があります。\n【感想まとめ】 良い点 軽い！（105g） 小さい（4.9 x 4.9 x 3.2 cm） 充電が早い（61Wで急速充電可能） 気になる点 ポートが1つ ケーブルは入っていない 【実際に購入した販売ページ（Amazon）】 RAVPower 61W USB-C 急速充電器（¥3,998）\nブラック\nホワイト\niPhone付属充電器との比較\nRAVPower 90W 2ポートUSB-C 急速充電器（RP-PC128）：おすすめ度 ★★★ 上記のRP-PC112のところでも書きましたが、Type-Cを使って充電をする事が増え「ポート増やしてぇ」と思うことが増えました。特にiPhone11を購入してからiPhone11を急速充電しつつThinkPadの急速充電もしたいと思い、2ポートの充電器を探していました。そこで同じRAVPowerで探して、購入したものがこちらの「RAVPower 90W 2ポートUSB-C 急速充電器（RP-PC128）」になります。\n2ポートで合計90Wの出力が可能ですので、ThinkPadとiPhone11の同時急速充電ができます。もちろん1ポートのみ使用する際は90Wでの出力が可能です。\nこの違いに関しては下の写真を見ていただくと、出力W数が変わっていることを確認していただけると思います。\n重さと大きさについては、195g・6.5 x 6.5 x 3.2 cmとなっています。\nこの商品のお得な点はRP-PC112と違って、Type-C to Type-Cのケーブルが1本同梱されていることです！\n私は下で紹介するAnkerのケーブルを買いましたが、ケーブルどうすればいいかなって方はRP-PC112ではなく、こちらを買ってもいいかもしません。総じてお得な商品になっています。\n【感想まとめ】 良い点 そこそこ軽い！（195g） そこそこ小さい（6.5 x 6.5 x 3.2 cm） 充電が早い（最大90Wで急速充電可能） ポートが2つ 気になる点 特になし 【実際に購入した販売ページ（Amazon）】 RAVPower 90W USB-C PD対応充電器 PD3.0対応 RP-PC128（¥5,399） type-c to type-cもついている\nRP-PC112との比較\n接続ポート数に合わした給電\nAnker PowerLine+ III USB-C \u0026amp; USB-C 2.0 ケーブル (1.8m ブラック) ：おすすめ度 ★★★ 最後に紹介するのがこちらのケーブルになります。\nRP-PC112を購入する際にケーブル買わないとということで、高速充電に対応しているケーブルを購入しました。かい性能は下記販売ページにて確認していただければと思いますが、素材が折り曲げに強い素材（35,000回の折り曲げテストをクリアしているそう）かつ柔軟で使いやすいケーブルになっています。\nRP-PC128に付属しているケーブルは若干クセが強いため、使いづらさがありますのでケーブルとしてはこちらのほうが好きです。また、ケーブルをまとめるバンドもついていますのでそのあたりも推しポイントになります。\n【感想まとめ】 良い点 ケーブルが丈夫で曲げやすい 止めるバンドがついている 長さがいくつかのパターンで売られている 気になる点 特になし 【実際に購入した販売ページ（Amazon）】 Anker PowerLine+ III USB-C \u0026amp; USB-C 2.0 ケーブル（¥1,690） 丈夫なケーブル\n最後に 今回2020年に買ってよかったものをまとめていきましたが、実は他にもBeatsのヘッドフォンや、Anker系の製品を買ったりしています。\nこういったガジェットの話は結構好きなので、今後は購入次第、ひとつひとつを丁寧にまとめていこうかなと思いました（笑）。\n余談ですが、この記事を書いている途中でヴィッセル神戸がACL敗退となりとても落ち込んでいます\u0026hellip;。\n","description":"2020年に買ってよかったもの（充電機器）","id":21,"section":"posts","tags":["ガジェット"],"title":"2020年に買ってよかったもの vol.2","uri":"https://rakuichi4817.github.io/posts/glad-to-buy2/"},{"content":"最近は研究室時代にあまり丁寧に理解しようとしていなかったDeep系のお話や、Pythonでのシステム開発（テストとか）を学んでいるところです。\n久しぶりの更新なので、日本語を書く練習も兼ねて軽い話題にします。タイトル通り、今年「買ってよかったなぁ」と思うものを書いていきます。\n2回に分けて書いていきますが、紹介するものを以下にリストアップしています。今回触れるものは太文字にしています。\nガジェット系 iPhone11 128GB mujina PCスタンド Razer Hammerhead Pro V2 （RZ04-01730100-R3A1） RAVPower 61W USB-C 急速充電器（RP-PC112） RAVPower 90W 2ポートUSB-C 急速充電器（RP-PC128） Anker PowerLine+ III USB-C \u0026amp; USB-C 2.0 ケーブル (1.8m ブラック) その他 SNOOPY 転写ステッカー AfternoonTea PEANUTS/ステンレスマグカップ ノートカバー ガジェット系 コロナの影響で家にいるせいか、ポチポチ買ってしまった物が多いです。実際便利に使えているものが多いので良いのですが\u0026hellip;\niPhone11（128GB）：おすすめ度 ★★☆ iPhone8（写真右側）をずっと愛用していましたが、今更ながらiPhone11（写真左側）を買いました。\n「iPhone12も出るしiPhone12買うかぁ」と思っていたのですが、5G契約必須と言うことで12を買わずに11にしました。\n【ネットで見た意見】\n指紋認証がないから不便 大きすぎて不便 こんな感じの意見をネットで見ていましたが、実際に使ってみてこの画面の大きさに慣れるとむしろ8では小さく感じてしまいます。情報収集を電車などの移動中にする方は11のほうがサイズ的にはいいかもしれません。\nちなみに今まではdocomo オンラインショップで買っていましたが、今回はApple Storeで購入しました。おそらく本体価格だけで言うなら2万円近く安くなったのかなぁと思います。\n加えて、Rakuten Rebates経由でApple Storeにアクセスすることで、クレジットカードにもともとつくポイントとは別にポイントをもらえたのでかなりお得でした。本体代も一括で買っておけば、契約変更やキャリア乗り換えもしやすそうなので、これからはApple Storeで買おうと思います。\n【感想とまとめ】\n確かにマスクで顔認証がうまく行かないのはちょっとめんどくさい時がある 画面の大きさになれると8では小さく感じる なんだかんだ11で良かった 端末はApple Storeで買おう mujina PCスタンド：おすすめ度 ★★★ 今年買ったものの中でも特におすすめの商品です。先にまとめを書きます！\n高さがちょうど良い 持ち運びが楽 安い（2,000円前後） ThinkPadと相性が良い！ 今まではikeaのラップトップスタンド（BRÄDA ブレーダ）を使っていたんですが、自分が愛用しているThinkPadシリーズとは多少相性が悪く感じていました。\nスタンドの角度が若干きついせいか、ThinkPadのキーボードの打つ感じ（ストローク？）が浅くなっているように感じたのです。また、持ち運びもしたいなぁとも思っていたので、持ち運びができるスタンドを探していました。そこで見つけたのが「mujina pcスタンド（Amazon購入ページ）」です。\n「mujina pcスタンド」は下の写真のように組み合わせて持ち運ぶことができますし、1つのスタンドの高さが2cmで、程よく高さを調整してくれます。なお、直径は4cmになってます。\n特に愛用するThinkPadシリーズのキーボードと相性がよく、打心地がちょうどよく感じます。また、持ち運びもしやすいため、出先で作業する際にも活躍していますし、iPadなどにも利用できるのでものすごく便利です。\n2,000前後で買えるのでとりあえず買ってみても良いかと思います。今年買った中でもトップレベルに気に入っている商品です。\nmujina pcスタンド1\nmujina pcスタンド2\n実際に使って見た\nその他 ガジェットではないですが、買ってよかったなぁと思うものです。\nSNOOPY 転写ステッカー：おすすめ度 ★★☆ スヌーピーが好きでガジェット類も好きなので、スヌーピーのステッカーを買ってよく貼っていました。特に今年は初めてThinkPadを買ったので、「自分のPCにステッカーを貼ろう！」と決めていました（笑）。ここで、ステッカーを貼ろうとしたときに、白い余白みたいなのがあると嫌なので、転写ステッカーを使ってみました。転写ステッカーは余分な部分がないステッカーになっており、個人的にはThinkPadと合っていておしゃれだなぁと思っています。実際に買ったステッカーのリンクは以下においておきます。ただ、しっかり貼らないと、貼り付け部分が小さい分剥がれてしまうこともあります。実際他のガジェットに貼ったスヌーピーはぼろぼろになってしまいました\u0026hellip;\n寝転んでる方のステッカーのAmazonページ 走ってる方のステッカーののAmazonページ 【感想とまとめ】\n一般的なステッカーのように余分な部分がないからシンプルでガジェットに合う 剥がれやすいときもあるのでおすすめ度は★2つ 貼ってみた\nロゴとスヌーピー\nかわいい\nAfternoonTea PEANUTS/ステンレスマグカップ：おすすめ度 ★★★ 会社もほとんど在宅勤務になり、取っ手付きのマグカップが欲しいなぁと考えていました。そこでたまたま見つけたのが、「AfternoonTea PEANUTS/ステンレスマグカップ」になります。\n蓋がついていて、飲み口もついています。また、底に滑り止めがついており転倒しにくくなっています！\n何より“可愛い”です（可愛いは正義）\nお値段は¥3,080ですが、スヌーピー好きなら買う価値はあると思いますよ！\n【販売サイト】AfternoonTea LIVIG\nノートカバー：おすすめ度 ★★☆ 会社に入って検定系の勉強をし始め、普段はiPadでメモをとるのですが、ノートを使うことが増えてきました。ノートを裸で使うよりノートカバーがほしいなぁと思っていたところ、ふらっと寄ったお店に売っていたので衝動買いしました。\n利便性でいうとなくてもいいかなというのが正直な感想ですが、かっこいいので満足です（笑）。\n便利なところでいうとノート2冊をカバー内に挟んだり、髪資料を挟むことができるので、そのあたりは役に立ってるなと感じます。\nただやはり “かっこいいから”というのが最大の利用理由です。\n勉強意欲が湧いたり、外で自分のノート見直す気になります。\nノートカバー\n開いた様子\nまとめ こうやってまとめていくと、自分がやたらスヌーピーグッズを買ってるのがわかります（笑）。他にも巾着とかいっぱい買ってました。\nヴィッセル関連グッズもいくつか買ったんですが、やはりコロナの影響で試合にあまり見に行けず、出番は少なかったなぁと思います。\n次回はガジェット中心の紹介をする予定です。頑張って書こう\u0026hellip;\n","description":"2020年に買ってよかったもの（mujina pcスタンド等）","id":22,"section":"posts","tags":["ガジェット","日用品"],"title":"2020年に買ってよかったもの vol.1","uri":"https://rakuichi4817.github.io/posts/glad-to-buy1/"},{"content":"今回はUbuntuにElastic Stackを導入する手順について記録も兼ねて書いていこうと思います。\nElastic Stackは、Elasticsearch、Kibana、Beats、Logstashの4つのツールの総称です。公式サイトに書かれている各ツールの説明は以下のとおりです。\nElasticsearch 特定のIPアドレスによるアクティビティを確認する、あるいはトランザクションリクエストのスパイクを分析する、または半径2キロ以内にある牛丼店を探す\u0026hellip; データを使って解くあらゆる\u0026quot;課題\u0026quot;は、最終的に検索の課題です。Elasticsearchなら、データを手軽に、スケーラブルに格納、検索、分析することができます。\nKibana Kibanaでデータを美しく可視化して、探索をはじめてみましょう。ワッフルチャートやヒートマップ、時系列分析など、豊富な機能が揃います。多様なデータソースに対応する事前構成済みのダッシュボードを使って、KPIに注目したプレゼンテーションを作成したり、1つの画面ですべてのデプロイを管理したりすることもできます。\nBeats Beatsは、データシッピングに特化した無料かつオープンなプラットフォームです。何百、何千ものマシンからLogstashやElasticsearchにデータを転送できます。\nLogstash Logstashは、オープンソースのサーバーサイドデータ処理パイプラインです。膨大な数のソースから同時にデータを取り込み、変換して、お好みの格納庫（スタッシュ）に送信します。\nこの中でもElasticsearch、Kibana、Logstashの3つをインストールしていきます。\n環境 今回導入する環境と、インストールしたバージョンは以下のとおりです。\nUbuntu 18.04.4 LTS Java 1.8.0_252 Elasticsearch 7.8.0 Kibana 7.8.0 Logstash 7.8.0 インストールの手順 インストールの手順は以下になります。\nJavaのインストール Elasticsearchのインストール Kibanaのインストール Logstashのインストール 1. Javaのインストール ElasticStackはJavaを入れておかないと動かないので入れておきます。\n1 2 add-apt-repository ppa:webupd8team/java sudo apt install openjdk-8-jre-headless 確認\n1 2 3 4 $ java -version openjdk version \u0026#34;1.8.0_252\u0026#34; OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09) OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode) 2. Elasticsearch 2.1. インストールと自動起動設定 Javaが正しくインストールできたら、下記コマンドでElasticsearchのインストールをします。\n1 2 3 4 wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - sudo apt install apt-transport-https echo \u0026#34;deb https://artifacts.elastic.co/packages/7.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list sudo apt update \u0026amp;\u0026amp; sudo apt install elasticsearch 自動で立ち上がるように設定します。\n1 2 sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service 2.2. 外部接続用に設定の変更 外部PCからアクセスするための設定を行います。まずはじめにポートの開放を行います。\n1 2 sudo ufw allow 9200 sudo ufw allow 9300 下記コマンドで、Elasticsearchの設定を書き換えます。\n1 sudo nano /etc/elasticsearch/elasticsearch.yml 以下の内容を加えます。\n1 2 network.bind_host: 0 discovery.seed_hosts: [\u0026#34;127.0.0.1\u0026#34;, \u0026#34;[::1]\u0026#34;] 2.3. 再起動、状態と接続の確認 設定を書き換えたら、Elasticsearchの再起動を行います。\n再起動後、起動状態の確認も行います。Activeのところに「active」と書かれていれば正しく動いています。\n1 2 3 4 5 6 7 8 9 10 11 12 $ sudo systemctl restart elasticsearch.service $ sudo systemctl status elasticsearch.service ●elasticsearch.service - Elasticsearch Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: ena Active: active (running) since Sun 2020-06-21 15:50:49 JST; 2h 1min ago Docs: https://www.elastic.co Main PID: 3447 (java) Tasks: 110 (limit: 4915) CGroup: /system.slice/elasticsearch.service ├─3447 /usr/share/elasticsearch/jdk/bin/java -Xshare:auto -Des.networkaddress.cach └─3642 /usr/share/elasticsearch/modules/x-pack-ml/platform/linux-x86_64/bin/contro \u0026lt;サーバのIPアドレス\u0026gt;:9200で外部からアクセス可能か確認することができます。接続すると以下のような内容が表示されるはずです。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \u0026#34;name\u0026#34; : \u0026#34;\u0026lt;サーバ名\u0026gt;\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;\u0026lt;cluster_uuid\u0026gt;\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;7.8.0\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;deb\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;\u0026lt;build_hash\u0026gt;\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2020-06-14T19:35:50.234439Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;8.5.1\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; } 3. Kibana 3.1. インストールと自動起動設定 インストールと自動起動設定は下記コマンドで可能です。\n1 sudo apt install kibana Kibanaの自動起動設定\n1 2 sudo systemctl daemon-reload sudo systemctl enable kibana.service 3.2. 外部接続用に設定の変更 Elasticsearchと同様に外部PCからアクセスするための設定を行います。\nまずはじめにポートの開放を行います。\n1 sudo ufw allow 5451 下記コマンドで、Kibanaの設定を書き換えます。\n1 sudo nano /etc/kibana/kibana.yml 以下のよう一部を書き換えます。\n1 server .host : \u0026#34;0.0.0.0\u0026#34; 3.3. 再起動、状態と接続の確認 設定を書き換えたら、Kibanaの再起動を行います。\n再起動後、起動状態の確認も行います。Activeのところに「active」と書かれていれば正しく動いています。\n1 2 3 4 5 6 7 8 9 10 $ sudo systemctl restart kibana.service $ sudo systemctl status kibana.service ● kibana.service - Kibana Loaded: loaded (/etc/systemd/system/kibana.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2020-06-21 15:42:32 JST; 3h 5min ago Main PID: 860 (node) Tasks: 11 (limit: 4915) CGroup: /system.slice/kibana.service └─860 /usr/share/kibana/bin/../node/bin/node /usr/share/kibana/bin/../src/cli ここまでくれば、「\u0026lt;サーバのIPアドレス\u0026gt;:5601」でKibanaの画面を確認できます。\nKibana画面\n4. Logstash 4.1. インストールと自動起動設定 インストールと自動起動設定は下記コマンドで可能です。\n1 sudo apt install logstash 自動起動設定\n1 2 sudo systemctl daemon-reload sudo systemctl enable logstash.service 4.2. Logstashの設定書き換え Web上の解説サイトでは /etc/logstash/conf.d/ 配下に .conf ファイルを置くと、設定が読み込まれてデータの投入ができると書いているところもありますが、どうやら現在のバージョンでは、自ら明示的に書いてやらないといけないようです。\n変更部分はLogstash本体の設定ファイル/etc/logstash/logstash.yml内のpath.config:の部分を以下のように書き換えます。\n1 sudo nano /etc/logstash/logstash.yml 1 2 3 4 # 元の状態 # path.config: # ↓書き直した後 path.config: /etc/logstash/conf.d まとめ 今回は、Elasticstackのインストール方法についてまとめました。\n今後、自分が持っているテキストデータなどをElasticでインデクシングして、活用していこうと思います。\n","description":"UbuntuにElasticstackを導入してみます","id":23,"section":"posts","tags":["Elastic","環境構築"],"title":"Ubuntu 18.04.4 LTSにElasticsearch、Logstash、Kibanaを導入","uri":"https://rakuichi4817.github.io/posts/install-elasticstack/"},{"content":"Java勉強記録第3回の今回は、キーボード入力と、文字列の連結についてまとめていきます。文字列の連結の仕方を工夫しないと、データ量が増えたときに処理が遅くなったりしますからね。\nキーボード入力の受付 Javaのキーボード入力の受付には、java.util パッケージの Scanner クラスを用います。\n今回の入力には以下の3つのメソッドを利用しています。\nnextInt()：整数型の入力 nextDouble()：少数型の入力 nextLine()：文字列の入力 ここで、気をつけないといけないことはnextInt()やnextDouble()で数字を読み込んだ際に、改行文字（Enterを押すため）が残る点です。\nそのままnextLine()を使うと、その改行文字を読み込んで処理が終わってしまいます。ですので、nextLine()を間に一度入れることで空読みを行い、この問題を解決します。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import java.util.Scanner; public class Keybord{ public static void main(String[] args){ // Scannerクラスの呼び出し Scanner scan = new Scanner(System.in); // 数値の入力 System.out.print(\u0026#34;int型を入力：\u0026#34;); int num1 = scan.nextInt(); System.out.print(\u0026#34;duble型を入力：\u0026#34;); double num2 = scan.nextDouble(); // 空読み scan.nextLine(); // 文字列の入力 System.out.print(\u0026#34;String型を入力：\u0026#34;); String strin = scan.nextLine(); // 入力の確認 System.out.println(\u0026#34;【入力の確認】\u0026#34;); System.out.println(\u0026#34;int型：\u0026#34; + num1); System.out.println(\u0026#34;double型：\u0026#34; + num2); System.out.println(\u0026#34;String型：\u0026#34; + strin); } } このプログラムを実行した結果が以下のとおりです。うまく機能していることを確認できました。\n1 2 3 4 5 6 7 int型を入力：1 duble型を入力：10.0 String型を入力：vissel 【入力の確認】 int型：1 double型：10.0 String型：vissel 文字列の連結 文字列の連結には下記の通りいくつか種類があります。\nプラス演算子 concat() join() StringBuffer StringBuilder プラス演算子や、concat()の他にも、StringBufferやStringBuilderといったクラスを利用することで連結することができます。StringBufferやStringBuilderの2つの違いに関しては以下の記事を参考にしていただければ良いと思います。\n今回はとりあえず一般的に処理が早いStringBuilderを利用します。\n参考サイト：文字列操作 スレッドセーフ vs パフォーマンス StringBuilder\nプラス演算子や、concat()による連結処理は重いみたいです。特にプラス演算子でつなげるとめちゃくちゃ遅いみたいですね。今回、時間は計測していませんが、以下のQiitaの記事を見るとプラス演算子がいかに遅いかがわかると思います。\n参考サイト： 【Java】文字列結合の速度比較\nプラス演算子 つなげたい変数や文字列を+でつなぎます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class StringJoin { public static void main(String[] args) { // 文字列の連結 String s1, s2, s3, sjoin; s1 = \u0026#34;ヴィッセル神戸\u0026#34;; s2 = \u0026#34;天皇杯\u0026#34;; s3 = \u0026#34;優勝\u0026#34;; System.out.printf(\u0026#34;s1 = %s\\n\u0026#34;, s1); System.out.printf(\u0026#34;s2 = %s\\n\u0026#34;, s2); System.out.printf(\u0026#34;s3 = %s\\n\u0026#34;, s3); // プラスで sjoin = s1 + s2 + s3; System.out.println(\u0026#34;\\nプラス演算子\u0026#34;); System.out.println(sjoin); } } 出力結果は以下のとおりです。\n1 2 3 4 5 6 s1 = ヴィッセル神戸 s2 = 天皇杯 s3 = 優勝 プラス演算子 ヴィッセル神戸天皇杯優勝 concat() s1に対してs2を連結させたい場合はs1.concat(s2)とします。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class StringJoin2 { public static void main(String[] args) { // 文字列の連結 String s1, s2, s3, sjoin2; s1 = \u0026#34;ヴィッセル神戸\u0026#34;; s2 = \u0026#34;天皇杯\u0026#34;; s3 = \u0026#34;優勝\u0026#34;; // concat sjoin2 = s1.concat(s2); sjoin2 = sjoin2.concat(s3); System.out.println(\u0026#34;\\nconcat\u0026#34;); System.out.println(sjoin2); } } 出力結果は以下のとおりです。\n1 2 concat ヴィッセル神戸天皇杯優勝 join() join()を用いることで、複数の文字列型を一つにつなげることができます。第一引数に設定した値が、連結する文字型の間に入ります。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class StringJoin3 { public static void main(String[] args) { // 文字列の連結 String s1, s2, s3; s1 = \u0026#34;ヴィッセル神戸\u0026#34;; s2 = \u0026#34;天皇杯\u0026#34;; s3 = \u0026#34;優勝\u0026#34;; // joinメソッド String sjoin3 = String.join(\u0026#34;-\u0026#34;, s1, s2, s3); System.out.println(\u0026#34;\\njoin\u0026#34;); System.out.println(sjoin3); } } 出力結果は以下のとおりです。\n1 2 join ヴィッセル神戸-天皇杯-優勝 StringBuilder StringBuilderクラスを用いて、append()していくことで連結できます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class StringJoin4 { public static void main(String[] args) { // 文字列の連結 String s1, s2, s3; s1 = \u0026#34;ヴィッセル神戸\u0026#34;; s2 = \u0026#34;天皇杯\u0026#34;; s3 = \u0026#34;優勝\u0026#34;; // StringBuilder append StringBuilder sjoin4 = new StringBuilder(); sjoin4.append(s1); sjoin4.append(s2); sjoin4.append(s3); System.out.println(\u0026#34;\\nStringBuilder append\u0026#34;); System.out.println(sjoin4); } } 出力結果は以下のとおりです。\n1 2 StringBuilder append ヴィッセル神戸天皇杯優勝 まとめ キーボードからの入力の受け取りと、文字列の連結についてまとめました。正直な感想は、「Pythonの方がええなぁ」です（笑）。\nとはいっても、システムを作る時にJavaの良さが生きるときもあると思うので、しっかり理解していきたいと思います。\n","description":"Javaでのキーボード入力と文字列の連結についてまとめました","id":24,"section":"posts","tags":["Java"],"title":"【Java勉強-第4回】キーボード入力と文字列の連結","uri":"https://rakuichi4817.github.io/posts/study-java04/"},{"content":"【2021年9月18日追記】\n本記事ではcondaを用いて仮想環境を作成し、その内部でpipを使ってライブラリをインストールしています。しかし、2021年途中以降で脱Anacondaをしましたので、こちらの方法がおすすめというわけでもありません。 こんばんは、4月から始まった会社の研修も、Zoomによるリモート研修になってしまい、一日中パソコンとにらめっこしているRakuichiです。\n会社ではJavaの勉強をするので、せっかく大学院で利用してきたPythonの感覚を鈍らせないためにも、Keras（TensorFlow）を用いたディープラーニングの勉強をすることにしました。\n私は意地でもWindowsマンで、WindowsのCPU版での環境を作りましたので、今回はそれをまとめたいと思います。\n他のネットブログ等にはインストール時のバージョンなどが書かれていないこともあるので、この記事ではしっかり記しておきたいと思います。\nKerasとTensorFlowの説明に関しては省きますが、KerasはTensorFlowのAPIであり、TensorFlowが必須となります。\n環境 記事作成時の私の環境は以下になります。\nラップトップでGPUがないので、CPU版での環境構築になります。\nまた、開発にはJupyter Labを利用しているためそちらの設定も行います。\nWindows10 Pro （CPUのみ） Anaconda3 Jupyter Lab Python 3.6 TensorFlow 2.1.0 Keras 2.3.1 インストールの手順 インストールの手順は以下になります。\nAnacondaで仮想環境の作成 conda環境の切り替えとJupyter上のカーネルの登録 「Visual C++ Build Tools 2019」のインストール 「TensorFlow」のインストール 「Keras」のインストール 私が個人的にハマったポイントは、3つ目のVisual C++ Build Tools 2019を入れてなかった点です。このため、TensorFlowのインストールはうまくいくのに、Pythonでインポートができない問題が発生しました。\n（新しいPCに変えて入れるの忘れてましたが、こいつを入れていないと色んなもののインストール時に問題が発生します。）\n1. Anacondaでの仮想環境の作成 KerasとTensorFlowには対応したPythonのバージョンが存在しているため、普段使っているPythonのバージョンでは動かない可能性があります。そのため、Anacondaの仮想環境機能を利用して、適したPythonバージョンの環境を作成します。\nここで、TensorFlowとKerasの公式サイトよりPythonの対応バージョンを見てみます。\nPython 3.5–3.7\nTensorFlow公式サイトより\nKerasはPython 2.7-3.6に対応しています．\nKeras公式サイトより\nこの両方を満たすPythonのバージョンのなかから、今回はバージョン 3.6 で環境を作ります。\ncondaの仮想環境を作成するためにコマンドプロンプト上で以下のコマンドを入力します。意味としては、「keras-cpu」という名のAnaconda環境を作成し、「Pythonバージョンの3.6」と「Jupyter」をインストールすることになります。\n1 conda create -n keras-cpu python=3.6 jupyter 2. conda環境の切り替えとJupyter上のカーネルの登録 作成した環境に切り替える方法と、Jupyter上で環境を切り替える方法について述べていきます。\nコマンドプロンプト（コンソール上）でのconda環境の切り替えは以下のとおりです。\n1 activate keras-cpu コマンド実行後、C:\\Users\\ユーザ名\u0026gt; の前に (keras-cpu) が入れば切り替え完了です。\n続いて、Jupyter上でカーネルを切り替えるための設定をします。上記コマンドで環境を切り替えた状態で以下のコマンドを実行します。\n1 ipython kernel install --user --name=keras-py3.6 --display-name=keras-py3.6 このコマンドにより、今適応されているconda環境がJupyter上で切り替えられるようになります。\n「\u0026ndash;display-name=」に続けて書かれたものが、Jupyter上で表示されます（多分）。\n実際、登録後にJupyter Labを起動してみると、以下のようにPythonのKernelに、もともと存在していた「Python 3」と、新たに作成した「keras-py3.6」の2つが出てきます。\nKeras等をインストールしたあとは、この新しく作成したKernelを利用して実行するようにしてください。\nJupyter Labの画面\n3. 「Visual C++ Build Tools 2019」のインストール こちらをインストールしていない状態でTensorFlowとKerasをインストールすると、インストールはうまくいくものの、いざPythonでインポートするとエラーを吐いて動かない、ということになります。\n公式のTensorFlowのWindowsに関するページを見ると、以下のように書かれています。こちらに従って、必要なものをインストールしてください。\nVisual C++ Build Tools 2019 をインストールする Visual C++ Build Tools 2019 をインストールします。これは Visual Studio 2019 に付属していますが、別々にインストールすることもできます。\nVisual Studio のダウンロード サイトに移動します。 再頒布可能パッケージおよびビルドツールを選択します。 以下をダウンロードしてインストールします。 Microsoft Visual C++ 2019 再頒布可能ファイル Microsoft Build Tools 2019 引用元： https://www.tensorflow.org/install/source_windows\n4. TensorFlowのインストール 以上の手順が終わり次第、 pip を使ってTensorFlow（バージョン2.1.0）をインストールします。\nTensorFlowのバージョン1系では、CPU版とGPU版が分けられて扱われていますが、最新の2系では公式ページ（以下で引用）に記されている通り、両方に対応しているため、気にすることなくインストールが可能です。\nTensorFlow 2 パッケージが利用可能 tensorflow - 最新の安定版リリース、CPU および GPU サポート（Ubuntu、Windows 用）\nインストールする際には、activate keras-cpu をした状態で以下のコマンドを実行してください。関連パッケージなども勝手にインストールされます。\n1 pip install tensorflow 5. Kerasのインストール TensorFlowのインストールが無事終われば、Keras（バージョン2.3.1）は、以下のコマンドで問題なくインストール可能です。\n1 pip install keras 確認 すべての環境構築が終わればJupyter Labで「keras-py3.6」のKernelを選択し、\nいかのプログラムでインポートができれば完了です。\nおそらく「Keras」のインポート時には、バックエンドで何を使っているか（今回の場合はTensorFlow）が表示されると思います。\n1 2 import tensorflow import keras まとめ 今回はCPUのWindows環境で、Anacondaを用いたTensorFlowとKerasの環境構築について説明しました。\n比較的簡単にできるとは思いますが、Visual C++ Build Tools 2019をインストールしないといけないことが、落とし穴になっていたりするので注意していただければと思います。\n","description":"Windows上にAnacondaでKerasの環境を作成します","id":25,"section":"posts","tags":["Python","AI・ML","環境構築"],"title":"Windows(CPU)にAnacondaでTensorFlow2.1.0とKeras2.3.1の導入","uri":"https://rakuichi4817.github.io/posts/windows-cpu-keras/"},{"content":"Java勉強記録第3回の今回は、簡単なif・else文を試していこうと思います。\n今回は本当に触る程度で、今後実課題に取り組む時に（そんなときはこなさそう）、色々詳しく見ていこうかと思います。\n極力こまめに投稿しようとした結果、一回の内容が薄くなりがち\u0026hellip;\nif・else文 まず実例からということで、文字列型変数 team と team2 にそれぞれ「ヴィッセル神戸」と「vissel kobe」を格納。\n「ヴィッセル神戸」のときに、「最高です！」、そうでない時に、「!」を語尾に追加して出力するif・else文を作成しました。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class PracticeIf { public static void main(String[] args) { // 当てはまる時 String team = \u0026#34;ヴィッセル神戸\u0026#34;; if(team==\u0026#34;ヴィッセル神戸\u0026#34;) { System.out.println(team + \u0026#34;最高です！\u0026#34;); } else { System.out.println(team + \u0026#34;!\u0026#34;); } // 当てはまらない時 String team2 = \u0026#34;vissel kobe\u0026#34;; if(team2==\u0026#34;ヴィッセル神戸\u0026#34;) { System.out.println(team2 + \u0026#34;最高です！\u0026#34;); } else { System.out.println(team2 + \u0026#34;!\u0026#34;); } } } このプログラムを実行した結果が以下のとおりです。\n1 2 3 --出力結果-- ヴィッセル神戸最高です！ vissel kobe! このようにちゃんと条件分岐されていることがわかります。\nここでif・else文の基本的な使い方について見てみると以下のようになります。\n1 2 3 4 5 6 if(条件式) { Trueの場合の処理 } else { Falseの場合の処理 } ifの直後のカッコ内の条件式がTrueかFalseかで処理が分かれる最も簡単なif文です。\nこのあたりはC言語とそんな変わらないですね。\n条件式については、その他の言語と同様の比較演算子を用いる事ができます。\n比較演算子を用いた例を以下に示します。\nこれらは内容が正しければTrue、そうでなければFalseを返します。\n条件式 内容 a == b aとbが同じ a != b aとbが違う a \u0026gt; b aがbより大きい a \u0026gt;= b aがb以上 a \u0026lt; b aがbより小さい a \u0026lt;= b aがb以下 else if文でさらなる分岐 続いて、else ifを用いてifの条件式でFalseになった時に、さらなる条件式に当てはまるかどうかで処理を分岐させます。\n具体的なプログラムで見てみましょう。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class ForIf { public static void main(String[] args) { String tournament = \u0026#34;天皇杯\u0026#34;; // \u0026#34;ゼロックス\u0026#34;と\u0026#34;Jリーグ\u0026#34;の場合も検証 if(tournament==\u0026#34;天皇杯\u0026#34;) { System.out.println(tournament + \u0026#34;優勝！\u0026#34;); } else if(tournament==\u0026#34;ゼロックス\u0026#34;) { System.out.println(tournament + \u0026#34;優勝！\u0026#34;); } else { System.out.println(tournament + \u0026#34;今年こそ優勝！\u0026#34;); } } } この結果は以下のようになります。\n1 2 3 天皇杯優勝！ ゼロックス優勝！ Jリーグ今年こそ優勝！ まとめ 今回は、超単純なif文についてまとめました。\n入れ子とかinstanceof演算子等、色々他にもすべきことが大量にあるのですが、\nまた次の機会ということで\u0026hellip;。\n次回はfor文と配列についてかなと思います。\n","description":"Javaで簡単なif・else文を試してみました","id":26,"section":"posts","tags":["Java"],"title":"【Java勉強-第3回】簡単なif・else文","uri":"https://rakuichi4817.github.io/posts/study-java03/"},{"content":"お久しぶりです。\n修士論文やら学会に提出する論文やらで、ブログを更新するのをサボってしまっていました。\nさて、今回は第2回ということで、\nJavaの変数について色々基本的なことを学びましたので、まとめていこうと思います。\n随所でPythonになれきってしまった私が注意するポイントがありましたので、そのあたりを特に意識して記録していこうと思います。\n統合開発環境のEclipceを使った基本的な出力については、下記URLにて触れていますので、そちらをご覧ください。\n【Java勉強-第1回】EclipceでHello World!\n変数 今回使ってみた変数型は以下のとおりです。\n文字型（char） 文字列型（String） 整数型（int, long, short, byte） 少数型（float, double） boolean型（boolean） 文字型から触りだしたのは、\n普段研究でPythonを使ってテキストデータを扱っているので、一番感覚的に差が出るかなと思ったからです。\nPythonでは変数の型について、逐一定義する必要はなかったのですが、基本的にソッチのほうが珍しいですよね。\n文字型（char） 1文字のみ格納可能 char で定義 格納する文字は シングルクォーテーション「\u0026rsquo;」 で囲う 気をつけないといけないのは、\n格納する文字を必ずシングルクォーテーションでで囲うということですね。\nPythonでは考えないことなので注意が必要です。\n1 2 // 値の格納 char c = \u0026#39;あ\u0026#39;; 文字列型（String） 文字列を格納 String で定義 （一文字目が大文字） 格納する文字列は ダブルクオーテーション「\u0026quot;」 で囲う 最も気をつけないといけないのは、文字型の「char」とは違って、「String」の「S」が大文字であることです。\nまた、文字列型はダブルクオーテーション「\u0026quot;\u0026quot;」で囲う必要があります。\n文字型とは違うので気をつける必要があります。\n1 String s = \u0026#34;ヴィッセル神戸が大好き\u0026#34;; 整数型（int, long, short, byte） 整数を格納 byteで定義した場合は8ビット（-128 ~ 127） shortで定義した場合は16ビット（-32768 ~ 32767） int で定義した場合は32ビット（-2,147,483,648 ~ 2,147,483,647） longで定義した場合は64ビット（ -9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,807） longで定義した場合は値の語尾に 「L」または「l（小文字のエル）」 をつける 大文字推奨 ：小文字のエルは数字の「1」と間違う可能性があるため 気をつけるポイントはlongで指定した場合に、\n値の語尾に 「L」または「l（小文字のエル）」 をつけることです。\n小文字のエルは数字のいちと見間違えることがあるので、基本は大文字が推奨されているようです。ちなみに、小文字のエルと数字の1を並べるとこんな感じです 1l 。\nまた、それぞれの型で格納できる値が決まっています。これらの値を超えると 桁あふれ がおきます。\n1 2 3 4 5 6 7 int x , y, z; long lx, ly, lz; x = 1; y = 2; lx =100000L; ly =200000L; 桁あふれ 桁あふれについてどのような挙動を取るかを確認します。\nint 型の変数に格納できる最大値を格納し、その変数に+1したものを出力してみます。\nそうすると桁あふれが起きて、下記のように最小値が出力されています。\nこの桁あふれには注意しないといけません。\n1 2 3 4 5 6 7 8 9 10 11 // 格納できる最大値の格納 int max_num = Integer.MAX_VALUE; System.out.println(max_num); System.out.println(max_num + 1); --結果-- //最大値 2147483647 //桁あふれ後 -2147483648 少数型（float, double） 少数を格納 floatで定義した場合は32ビット単精度浮動小数点数 floatで定義した場合は値の語尾に「F」または「f」をつける doubleで定義した場合は64ビット単精度浮動小数点数 こちらは同じ数字でも小数を含むものを扱う場合に用います。\n1 2 3 4 5 6 7 float fx, fy, fz; double dx, dy, dz; fx = 0.01F; fy = 0.02F; dx = 0.0003; dy = 0.0004; 割り算について 数字を用いた演算子では + - * / % の5つがあると思います。\nここで気をつけないといけないのは割り算関係の / %の2つになります。\nまず整数型のintを用いた場合の挙動の確認してみます。\n例として1/2、5/2、1%2、5%2の結果について見てみます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int x , y, z; x = 1; y = 2; z = 5; System.out.println(x / y); System.out.println(z / y); System.out.println(x % y); System.out.println(z % y); --結果-- 0 // 1/2の結果 2 // 5/2の結果 1 // 1%2の結果 1 // 5%2の結果 ---- 整数型同士の割り算ではこのように、\n余りを出す割り算を行っていると考えることができます。\nそのため/では商が%では余りが演算結果となります。\n続いて少数型を用いた結果を見てみます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 float x , y, z; fx = 1F; fy = 2F; fz = 5F; System.out.println(fx / fy); System.out.println(fz / fy); System.out.println(fx % fy); System.out.println(fz % fy); --結果-- 0.5 // 1/2の結果 1.5 // 5/2の結果 1.0 // 1%2の結果 1.0 // 5%2の結果 ---- 少数型の場合は、/の場合、少数を使って割り切った結果を示します。\n%に関しては整数型のときと同様で、余りを出す割り算を行った場合の余りが結果となります。\nboolean型（boolean） true か false を格納する変数 if文とか使う時に利用するイメージです。\n1 2 boolean tflag = true; boolean fflag = false; まとめと感想 今回は変数について色々見てみましたが、\n久しぶりに変数型を宣言する言語に触れたので、懐かしさを感じました（笑）。\n文字型と文字列型のシングルクォーテーションとダブルクォーテーションの使い分けには、特に気をつけようと思います。\n次は簡単なfor文と条件分岐についてやっていこうかなと思います。\n","description":"Javaの変数について","id":27,"section":"posts","tags":["Java"],"title":"【Java勉強-第2回】変数について","uri":"https://rakuichi4817.github.io/posts/study-java02/"},{"content":"新年あけましておめでとうございます。\n4月から入社する会社でJavaを利用するので、\n先駆けて勉強していこうと思い、せっかくなので勉強の記録をまとめていこうと思います。\nあくまで記録なのでミスがあれば右下よりコメントお願いしますm(_ _)m\n今回は第1回ということで、Hello Worldを出力するまでを書いていきます。\nJavaとEclipceの導入 Javaの開発環境として、統合開発環境のEclipce\n（https://mergedoc.osdn.jp/）を利用しています。\n最新版は安定しない可能性があるので、今回は「Eclipce 4.8 Photon」を利用します。\nJavaのインストールとEclipceのインストールに関しては以下のページを参考にしました。\n参考ページ Javaのインストール（Windows）：https://eng-entrance.com/java-install-jdk-windows\nJavaのインストール（Mac）：https://eng-entrance.com/java-install-jdk-mac\nEclipceでいちからの「Hello World」 Eclipceが起動できた前提で、「Hello World」を出力するまでの記録です。\nあまり深く考えずに以下の通りに実行すれば「Hello World」を出力できると思います。\n1. プロジェクトの作成 プロジェクトを作成することで、\nソースコードや関連パッケージを一つにまとめて管理することができるようです。\n左上の「新規」をクリック 「Javaプロジェクト」の選択後「次へ」 新規プロジェクトの作成\nプロジェクト名「JavaPractice」にして「完了」\nプロジェクト名の入力\nパッケージ・エクスプローラーのタブに「JavaPractice」ができる\n作成されたプロジェクトの確認\n2. パッケージの作成 「JavaPractice」で右クリック➝「新規」➝「パッケージ」をクリック\nパッケージの作成\n名前のところに「practice01」と入力し完了をクリック\nパッケージ名の入力\n3. クラスの作成 いよいよJavaファイルの作成です。\n作成した「practice01」を右クリック➝「新規」➝「クラス」をクリック\n新規クラスの作成\n名前に「HelloWorld」と入力し「public static void main(Staing[] args)」にチェックを入れる➝「完了」\nクラスの名の頭文字は大文字にする（単語が複数続く場合は頭文字を大文字にしてつなげる）\n新規クラスの設定\n以下のように表示される\nこのウィンドウでは右側にソースコードがあります\nクラス作成後の表示\n4. Hello Worldの出力 Hello Worldを出力するためのプログラムを書きます。\n以下のようにソースコードを書く\n細かい説明は抜きにしますが、print ではなく println を用いることで末尾に自動で改行が入ります 1 2 3 4 5 6 7 8 package practice01; public class HelloWorld { public static void main(String[] args) { // printlnは改行が末尾に入る System.out.println(\u0026#34;Hello World\u0026#34;); } } 実行ボタンを選択し左下のコンソールに「Hello World」が出力されているか確認する\nこのときうまく実行できない場合は「アウトライン」タブ内の、\n「HelloWorld」クラスを右クリックし「実行」をクリックする。\nプログラムの実行\nまとめと感想 今回は、Eclipseを使ってファイル作成から、\n定番の「Hello World」を出力するまでに取り組みました。\n普段Pythonしか触ってないので久しぶりに { } を見てC言語をやってた頃を懐かしみました笑。\nこれからもぼちぼち頑張っていこうと思います！\n次回は 「変数」 に取り組んでいく予定です。\n参考サイト サーチマン佐藤のJava\n","description":"Eclipceを使ってJavaでHello Worldを出力してみます","id":28,"section":"posts","tags":["Java",null],"title":"【Java勉強-第1回】EclipceでHello World!","uri":"https://rakuichi4817.github.io/posts/study-java01/"},{"content":"楽天レシピAPIを利用するときにカテゴリID一覧を作成したので一部載せておきます。\n利用した内容についてはまた機会があれば載せます。\n楽天レシピのカテゴリIDについて 楽天レシピのページ：https://recipe.rakuten.co.jp\n楽天ウェブサービス:APIのページ： https://webservice.rakuten.co.jp/document/\n上記の楽天APIを用いて楽天レシピにおけるカテゴリのIDを取得しました。\nカテゴリは階層構造になっているのですが、カテゴリのトップページURLを見ると、親子関係にあるカテゴリIDが - で繋がれています。\n例えば以下のような階層構造があるときに下の表のようになっています。\n人気メニュー ハンバーグ ハンバーグステーキ category_full_id category_name category_url 30 人気メニュー https://recipe.rakuten.co.jp/category/30/ 30-300 ハンバーグ https://recipe.rakuten.co.jp/category/30-300/ 30-300-1130 ハンバーグステーキ https://recipe.rakuten.co.jp/category/30-300-1130/ 楽天レシピのカテゴリ一覧 このページではカテゴリの量が多いので全ては載せていませんが、一覧を下記URLよりtsv形式でダウンロードできます。\nGithub: rakuichi4817/RelatedDataForRakutenAPI\n","description":"楽天レシピAPIのカテゴリについて","id":29,"section":"posts","tags":["RakutenAPI","Web"],"title":"楽天レシピのカテゴリID一覧","uri":"https://rakuichi4817.github.io/posts/rakuten-recipe-category/"},{"content":"Scikit-learnなどの外部パッケージを使わずに文書中の単語の出現回数を求めたいときのプログラムです。\n分かち書きされたテキスト ヴィッセル神戸のチャント（応援歌）の中でも、私が好きな「アウェイマーチ」をサンプルに試してみます。\nどこまでも行こうぜ 勝利を信じて\n熱き友の想い 胸に宿して\n行こう 勝利へ トモニ戦え ラーララ ララララ\n歌声響かせろ（神戸！） 遠く神戸まで（神戸！）\nさぁみんなで帰ろう 神戸に帰ろう 勝利この手に\n以上のテキストに対して、分かち書きを行うと以下のようになります。\n分かち書きとは、形態素と呼ばれる意味を持つ最小単位に分割することを言います。\n1 どこ まで も 行こ う ぜ 勝利 を 信じ て 熱き 友 の 想い 胸 に 宿し て 行こう 勝利 へ トモニ 戦え ラーララ ララララ 歌声 響かせろ （ 神戸 ！ ） 遠く 神戸 まで （ 神戸 ！ ） さぁ みんな で 帰ろ う 神戸 に 帰ろ う 勝利 この 手 に 標準ライブラリのcollections.Counterを利用する collections.Counter()にリストなどを与えると、Counterオブジェクトが生成されます。Counterは辞書型dictのサブクラス（同じような形）で、keyに要素、valueに出現回数を持ちます。\n1 2 3 4 5 6 from collections import Counter wakati_text = \u0026#34;分かち書きされた上記のテキストを入れる\u0026#34; morph_counts = Counter([morph for morph in wakati_text.split(\u0026#34; \u0026#34;)]) print(morph_counts) 出力は以下のようになります。\n1 Counter({\u0026#39;神戸\u0026#39;: 4, \u0026#39;う\u0026#39;: 3, \u0026#39;勝利\u0026#39;: 3, \u0026#39;に\u0026#39;: 3, \u0026#39;まで\u0026#39;: 2, \u0026#39;て\u0026#39;: 2, \u0026#39;（\u0026#39;: 2, \u0026#39;！\u0026#39;: 2, \u0026#39;）\u0026#39;: 2, \u0026#39;帰ろ\u0026#39;: 2, \u0026#39;どこ\u0026#39;: 1, \u0026#39;も\u0026#39;: 1, \u0026#39;行こ\u0026#39;: 1, \u0026#39;ぜ\u0026#39;: 1, \u0026#39;を\u0026#39;: 1, \u0026#39;信じ\u0026#39;: 1, \u0026#39;熱き\u0026#39;: 1, \u0026#39;友\u0026#39;: 1, \u0026#39;の\u0026#39;: 1, \u0026#39;想い\u0026#39;: 1, \u0026#39;胸\u0026#39;: 1, \u0026#39;宿し\u0026#39;: 1, \u0026#39;行こう\u0026#39;: 1, \u0026#39;へ\u0026#39;: 1, \u0026#39;トモニ\u0026#39;: 1, \u0026#39;戦え\u0026#39;: 1, \u0026#39;ラーララ\u0026#39;: 1, \u0026#39;ララララ\u0026#39;: 1, \u0026#39;歌声\u0026#39;: 1, \u0026#39;響かせろ\u0026#39;: 1, \u0026#39;遠く\u0026#39;: 1, \u0026#39;さぁ\u0026#39;: 1, \u0026#39;みんな\u0026#39;: 1, \u0026#39;で\u0026#39;: 1, \u0026#39;この\u0026#39;: 1, \u0026#39;手\u0026#39;: 1}) 標準ライブラリのcollections.defaultdictを利用する collections.defaultdict()を用いてカウントする方法もあります。\nこちらの方法であれば、柔軟に処理を付け加えることができるので、汎用性は高いかもしれません。\ndefaultdictについては、こちらの記事（Qiita: Python defaultdict の使い方）が参考になるかと。\n1 2 3 4 5 6 7 8 from collections import defaultdict # int型で初期化 morph_counts = defaultdict(int) for morph in wakati_text.split(\u0026#34; \u0026#34;): morph_counts[morph] = morph_counts[morph] + 1 print(morph_counts) まとめ 今回はストップワードなどを全く設定していないので、\n記号などが入っていますが、省く場合は以下の2通りの処理が考えられます。\n分かち書きの段階で品詞などにより残す単語を絞る 辞書型に入力するときにストップワード（正規表現）を用いて絞る ストップワードを簡易的に使うのであればSlothLibのテキストページを使うといいと思います。見やすくするにはワードクラウドとかを使ってみるのもいいですね。\n関連情報 SlothLib: Webサーチ研究のためのプログラミングライブラリ ","description":"外部パッケージを使わずに単語の出現回数をカウントします","id":30,"section":"posts","tags":["Python","NLP"],"title":"Pythonで分かち書きされたテキストに対する単語出現回数をカウント","uri":"https://rakuichi4817.github.io/posts/term-count/"},{"content":"久しぶりにHugoの投稿をしようと思います。\n今回の内容は、「マークダウン形式で書いたtableに対して、cssを適応させる」 です。\n通常のマークダウンで記入 例えば、マークダウン形式でテーブルを書くと、以下のようになります。\n1 2 3 4 5 | 選手 | 背番号 | 国 | | ------------------------ | ------ | -------- | | 古橋 亨梧 | 16 | 日本 | | アンドレス・イニエスタ | 8 | スペイン | | トーマス・フェルマーレン | 4 | ベルギー | ↓サイト上での表示↓\n選手 背番号 国 古橋 亨梧 16 日本 アンドレス・イニエスタ 8 スペイン トーマス・フェルマーレン 4 ベルギー 表示されるテーブルのデザインは、利用しているテンプレートに乗っ取る形になります。\n自作shortcodesで任意のcssを適応 自分で制作したcssをマークダウンで記入したテーブルに反映してみた結果が以下になります。\n苦肉の策みたいなやり方なので、他に良いやり方もあるかもしれません。\nまず、以下のようなshortcodeファイルを作成します。\n1 2 3 4 5 6 7 {{if (.Get \u0026#34;class\u0026#34;)}} \u0026lt;div class = \u0026#34;{{ .Get \u0026#34;class\u0026#34; }}\u0026#34;\u0026gt; {{ else }} \u0026lt;div class = \u0026#34;simple-table\u0026#34;\u0026gt; {{ end }} {{.Inner | markdownify }} \u0026lt;/div\u0026gt; 続いて、cssを以下のように作成します。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 div.simple-table table { width: 100%; border-top: 1px solid #e2e2e2; border-left: 1px solid #e2e2e2; background: #ffffff; margin-bottom:15px; margin-left: auto; margin-right: auto; color:#000000; } div.simple-table table th{ border-right: 1px solid #e2e2e2; border-bottom: 1px solid #e2e2e2; padding:10px 0; text-align: center; } div.simple-table table td { font-size: 0.9em; border-right: 1px solid #e2e2e2; border-bottom: 1px solid #e2e2e2; text-align: center; padding:10px 0; } div.simple-table table th { background-color: #f3f0f0; } そして、以下のようにマークダウンを記入します。\n1 2 3 4 5 6 7 {{\u0026lt; mdtable class = \u0026#34;simple-table\u0026#34; \u0026gt;}} | 選手 | 背番号 | 国 | | ------------------------ | ------ | -------- | | 古橋 亨梧 | 16 | 日本 | | アンドレス・イニエスタ | 8 | スペイン | | トーマス・フェルマーレン | 4 | ベルギー | {{\u0026lt; mdtable \u0026gt;}} これらを適応すると、以下のような表示になります。\n選手 背番号 国 古橋 亨梧 16 日本 アンドレス・イニエスタ 8 スペイン トーマス・フェルマーレン 4 ベルギー ざっくりとした説明 最初は{{replace}} を使って{{ {.Inner | markdownify }}で、マークダウン形式からマークアップに変換し、受け取った\u0026lt;table\u0026gt;の中身を書き換える方法を考えていました。\nしかし、あまりうまく動かず\u0026hellip;\nですので回避策として、shortcodes側で\u0026lt;table\u0026gt;の外側にクラスを適応した \u0026lt;div\u0026gt;をかまして、cssで対応させる手法をとりました。処理の流れ等の詳しい説明は今回は割愛します。\n参考ページ Hugo shortcodesドキュメント\n関連ページ 独自のショートコードを作成する | まくまくHugo/Goノート\n","description":"shortcodesを用いてtableになんとかcssを適応します","id":31,"section":"posts","tags":["Hugo","Web"],"title":"hugoでshortcodesを用いてtableにcssを適応","uri":"https://rakuichi4817.github.io/posts/hugo-table/"},{"content":"Rakuichi ヴィッセル神戸サポ。\n兵庫県内でIT屋さんとして働いてます。\n大学院では情報検索（主に商品検索）の研究をしていました。\n※本サイトでの発言は個人の見解であり、\n現所属、過去に所属していた組織とは関係がありません。\n使用言語等 【メイン】Python\n【経験有】C, Java, JavaScript, SQL, (html, css)\nブログのコンテンツ 技術系の備忘録 技術系の気になる記事や感想 個人で作ったアプリ ヴィッセル神戸🐮などの趣味関連 基本的には技術系の備忘録として運用していきます。\nたまには関係のないものも投稿すると思います。\nその他 プライバシーポリシー 当サイトに掲載されている広告について 当サイトでは、第三者配信の広告サービス（Googleアドセンス）を利用しています。\nこのような広告配信事業者は、ユーザーの興味に応じた商品やサービスの広告を表示するため、\n当サイトや他サイトへのアクセスに関する情報 『Cookie』\n(氏名、住所、メール アドレス、電話番号は含まれません) を使用することがあります。\nまたGoogleアドセンスに関して、このプロセスの詳細やこのような情報が、\n広告配信事業者に使用されないようにする方法については、こちらをクリックしてください。 サイトが使用しているアクセス解析ツールについて 当サイトでは、Googleによるアクセス解析ツール「Googleアナリティクス」を利用しています。\nこのGoogleアナリティクスはトラフィックデータの収集のためにCookieを使用しています。\nこのトラフィックデータは匿名で収集されており、個人を特定するものではありません。\nこの機能はCookieを無効にすることで収集を拒否することが出来ますので、お使いのブラウザの設定をご確認ください。\nこの規約に関して、詳しくはこちら、またはこちらをクリックしてください。 ","description":"RakuBlogについて","id":32,"section":"","tags":null,"title":"About","uri":"https://rakuichi4817.github.io/about/"},{"content":"Windows環境におけるHugoのインストール方法について紹介していきます。\n今回は、あまりこういった技術に慣れていない方向けに、丁寧めにまとめます。\nHugoとはGo言語で書かれた静的サイトジェネレータです。\nこのサイトもhugoを用いて作成していますが、私が使っていて感じるメリットは以下の点です。\nblog形式の静的サイトを簡単に高速に作成できる テーマが豊富で、適応も簡単なため、こだわりがなければすぐにサイトを作成できる 以前までhtmlをゴリゴリ書いていた私にとっては画期的なサイトジェネレータでした。\nchocolateyを用いたインストール chocolateyはLinuxでいう「apt」のようなパッケージ管理ツールです。\n（いろんなパッケージをコマンドを打つことで入れることができます）\n今回インストールするHugoはchocolateyを用いて簡単に入れることができます。\nchocolateyのインストール まず管理者用コマンドプロンプトを開く。\nWindowsキー(Windowsのマークが書かれたボタン)とrの同時押し 表示された入力欄※1に cmd を入力し ctrl shift Enter を同時押し 「このアプリがデバイスに変更を加えることを許可しますか」というメッセージが出てくるが気にせずOKを押す ファイル名を指定して実行: 出てきた画面（コマンドプロンプト）に、以下のコマンドをペーストすればインストールが始まります。始まらなければエンターをおしてください\n1 @\u0026#34;%SystemRoot%\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\u0026#34; -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command \u0026#34;iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://chocolatey.org/install.ps1\u0026#39;))\u0026#34; \u0026amp;\u0026amp; SET \u0026#34;PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\u0026#34; 表示の流れが終わればインストール完了です。\n続いて、以下のコマンドでchocolateyをアップデートしておいてください。\n1 choco upgrade chocolatey Hugoのインストール方法 chocolateyが入ってしまえば、Hugoは下記のコマンドで簡単にインストールすることができます。\nインストールする際に、通常版のhugoと、「Sass/SCSS」対応の拡張版hugo-extendがあります。私は利用するテーマの都合上、拡張版を選択しました。\n※とりあえず拡張版を入れておけば、問題ないのかな？と思っています\n1 choco install hugo-extended -confirm インストールできたか確認するために、バージョン確認のコマンドを実行します。\n以下のようにhugo versionと入力して、結果が帰ってきたらインストール完了です。\n1 2 \u0026gt; hugo version hugo v0.88.1-5BC54738+extended windows/amd64 BuildDate=2021-09-04T09:39:19Z VendorInfo=gohugoio 参考にしたページ chocolatey公式HP\nchocolatey公式HPパッケージ\nHugo公式HP\nHugo公式HPインストール方法\n","description":"Hugoのインストール方法について簡単にまとめます","id":33,"section":"posts","tags":["Hugo","Web","環境構築"],"title":"Hugoのインストール方法（Windows）","uri":"https://rakuichi4817.github.io/posts/install-hugo/"}]